{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"PGGAN_MOD.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"50r63IyuEOi9","colab_type":"code","outputId":"d980344b-de56-4697-e2ff-6113f9fee15b","executionInfo":{"status":"ok","timestamp":1562275513840,"user_tz":420,"elapsed":2458,"user":{"displayName":"Michael Jankowiak","photoUrl":"","userId":"13749907316228325380"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["print('Continue?(1=YES/0=NO)')\n","continue_training=bool(int(input()))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Continue?(1=YES/0=NO)\n","0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yfNyBoWsddhp","colab_type":"code","outputId":"e86f3100-f4c9-452e-8516-a93f2fc8f6f4","executionInfo":{"status":"ok","timestamp":1562253507790,"user_tz":420,"elapsed":40137,"user":{"displayName":"Michael Jankowiak","photoUrl":"","userId":"13749907316228325380"}},"colab":{"base_uri":"https://localhost:8080/","height":159}},"source":["from __future__ import absolute_import, division, print_function, unicode_literals\n","!pip install -q tensorflow-gpu==2.0.0-beta1\n","# import logging\n","# logging.getLogger('tensorflow').disabled = True\n","import tensorflow as tf\n","!pip install -q imageio\n","import glob\n","import imageio\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","import numpy as np\n","import PIL\n","import cv2\n","import random\n","import time\n","import shutil, os\n","from collections import deque\n","from tensorflow.keras import layers\n","\n","from IPython import display\n","from tqdm import tqdm\n","\n","# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n","\n","from google.colab import drive\n","drive.mount('/gdrive')\n","path = \"/gdrive/My Drive/GAN/\"\n","folder = \"PGGAN/PGGAN_MOD\""],"execution_count":0,"outputs":[{"output_type":"stream","text":["\u001b[K     |████████████████████████████████| 348.9MB 56kB/s \n","\u001b[K     |████████████████████████████████| 501kB 31.4MB/s \n","\u001b[K     |████████████████████████████████| 3.1MB 39.3MB/s \n","\u001b[?25h"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lLRM7t1wfe6I","colab_type":"code","outputId":"68b69dff-64ac-46da-fa85-e96b2e8111c8","executionInfo":{"status":"ok","timestamp":1562275540614,"user_tz":420,"elapsed":29212,"user":{"displayName":"Michael Jankowiak","photoUrl":"","userId":"13749907316228325380"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["imgs = []\n","files = os.listdir(path+\"pokemon/\")\n","random.shuffle(files)\n","file_range = 10 if len(files)-1 > 4000 else len(files)-1\n","for i in tqdm(range(0, file_range)):\n","    img = mpimg.imread(path+\"pokemon/\"+str(files[i]))\n","    imgs.append(img)\n","\n","def resize(images, size, BATCH_SIZE):\n","    i_list = []\n","#     for i in tqdm(images):\n","    for i in images:\n","        i = cv2.resize(i, (size, size), interpolation = cv2.INTER_AREA)\n","        i_list.append(i)\n","\n","\n","    train_images = np.array(i_list).astype('float32')\n","    train_images = train_images / 255\n","    BUFFER_SIZE = 60000\n","    train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n","    return train_dataset"],"execution_count":0,"outputs":[{"output_type":"stream","text":["100%|██████████| 868/868 [00:19<00:00, 45.33it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"Hp03skL805pn","colab_type":"code","outputId":"872aa16e-a7d4-4e27-ab2d-7449ea641c19","executionInfo":{"status":"ok","timestamp":1562275546456,"user_tz":420,"elapsed":35045,"user":{"displayName":"Michael Jankowiak","photoUrl":"","userId":"13749907316228325380"}},"colab":{"base_uri":"https://localhost:8080/","height":153}},"source":["class VAE_model(tf.keras.Model):\n","    @tf.function\n","    def __init__(self):\n","        super(VAE_model, self).__init__()\n","        \n","        self.relu = layers.LeakyReLU()\n","        self.sigmoid = layers.Activation('sigmoid')\n","        self.dropout = layers.Dropout(0.3)\n","        self.pool = layers.AveragePooling2D(strides=2, padding='same')\n","        self.gaus_noise = layers.GaussianNoise(.5)\n","        \n","        \n","        self.layer_512x512 = layers.Conv2D(16, (3, 3), strides=1, padding='same')\n","        self.layer_out_512x512 = layers.Conv2D(3, 1, strides=1, padding='same')\n","        \n","        \n","        self.layer_256x256 = layers.Conv2D(32, (3, 3), strides=1, padding='same')\n","        self.layer_out_256x256 = layers.Conv2D(3, 1, strides=1, padding='same')\n","        \n","        \n","        self.layer_128x128 = layers.Conv2D(32, (3, 3), strides=1, padding='same')\n","        self.layer_out_128x128 = layers.Conv2D(3, 1, strides=1, padding='same')\n","        \n","        \n","        self.layer_64x64 = layers.Conv2D(64, (3, 3), strides=1, padding='same')\n","        self.layer_out_64x64 = layers.Conv2D(3, 1, strides=1, padding='same')\n","        \n","        \n","        self.layer_32x32 = layers.Conv2D(64, (3, 3), strides=1, padding='same')\n","        self.layer_out_32x32 = layers.Conv2D(3, 1, strides=1, padding='same')\n","        \n","        \n","        self.layer_16x16 = layers.Conv2D(128, (3, 3), strides=1, padding='same')\n","        self.layer_out_16x16 = layers.Conv2D(3, 1, strides=1, padding='same')\n","        \n","        \n","        self.layer_8x8 = layers.Conv2D(128, 3, strides=1, padding='same')\n","        self.layer_out_8x8 = layers.Conv2D(3, 1, strides=1, padding='same')\n","\n","        \n","        self.layer_4x4 = layers.Conv2D(256, 4, strides=1, padding='same', name='layer_4x4')\n","        \n","        \n","        self.flatten = layers.Flatten()\n","        self.layer_out = layers.Dense(200, name='layer_out')\n","        \n","        \n","        self.op = tf.keras.optimizers.Adam(1e-4)\n","        self.fader_total = 500\n","        \n","\n","        noise = self.gaus_noise(tf.random.normal([1, 4, 4, 3]))\n","        output = self.model_4x4(noise)\n","        print(4, output[0].shape)\n","\n","        noise = self.gaus_noise(tf.random.normal([1, 8, 8, 3]))\n","        output = self.model_8x8(noise)\n","        print(8, output[0].shape)\n","\n","        noise = self.gaus_noise(tf.random.normal([1, 16, 16, 3]))\n","        output = self.model_16x16(noise)\n","        print(16, output[0].shape)\n","\n","        noise = self.gaus_noise(tf.random.normal([1, 32, 32, 3]))\n","        output = self.model_32x32(noise)\n","        print(32, output[0].shape)\n","\n","        noise = self.gaus_noise(tf.random.normal([1, 64, 64, 3]))\n","        output = self.model_64x64(noise)\n","        print(64, output[0].shape)\n","\n","        noise = self.gaus_noise(tf.random.normal([1, 128, 128, 3]))\n","        output = self.model_128x128(noise)\n","        print(128, output[0].shape)\n","\n","        noise = self.gaus_noise(tf.random.normal([1, 256, 256, 3]))\n","        output = self.model_256x256(noise)\n","        print(256, output[0].shape)\n","\n","        noise = self.gaus_noise(tf.random.normal([1, 512, 512, 3]))\n","        output = self.model_512x512(noise)\n","        print(512, output[0].shape)\n","        \n","        \n","        \n","        self.layer_4x4_vars = self.layer_out.trainable_weights + self.layer_4x4.trainable_weights\n","        self.layer_8x8_vars = self.layer_4x4_vars + self.layer_8x8.trainable_weights + self.layer_out_8x8.trainable_weights\n","        self.layer_16x16_vars  = self.layer_8x8_vars + self.layer_16x16.trainable_weights + self.layer_out_16x16.trainable_weights\n","        self.layer_32x32_vars = self.layer_16x16_vars + self.layer_32x32.trainable_weights + self.layer_out_32x32.trainable_weights\n","        self.layer_64x64_vars = self.layer_32x32_vars + self.layer_64x64.trainable_weights + self.layer_out_64x64.trainable_weights\n","        self.layer_128x128_vars = self.layer_64x64_vars + self.layer_128x128.trainable_weights + self.layer_out_128x128.trainable_weights\n","        self.layer_256x256_vars = self.layer_128x128_vars + self.layer_256x256.trainable_weights + self.layer_out_256x256.trainable_weights\n","        self.layer_512x512_vars = self.layer_256x256_vars + self.layer_512x512.trainable_weights + self.layer_out_512x512.trainable_weights\n","        \n","        \n","    @tf.function\n","    def model_4x4(self, inputs, fader=500, training=False):\n","        x = self.layer_4x4(inputs)\n","        x = self.relu(x)\n","        x = self.dropout(x, training=training)\n","        \n","        x = self.flatten(x)\n","        x = self.layer_out(x)\n","        \n","        mean, logvar = tf.split(x, num_or_size_splits=2, axis=1)\n","        eps = tf.random.normal(shape=mean.shape)\n","        z = eps * tf.exp(logvar * .5) + mean\n","        \n","        return z, mean, logvar\n","     \n","    @tf.function   \n","    def model_8x8(self, inputs, fader=500, training=False):\n","        \n","        old = self.pool(inputs) * 1-(fader/self.fader_total)\n","        \n","        x = self.layer_8x8(inputs)\n","        x = self.relu(x)\n","        x = self.dropout(x, training=training)\n","        x = self.layer_out_8x8(x)\n","        x = self.pool(x)\n","        x = self.sigmoid(x)\n","        \n","        x = x * (fader/self.fader_total)\n","        x = x + old\n","        \n","        x = self.model_4x4(x, training=training)\n","        \n","        return x\n","     \n","    @tf.function   \n","    def model_16x16(self, inputs, fader=500, training=False):\n","        \n","        old = self.pool(inputs) * 1-(fader/self.fader_total)\n","        \n","        x = self.layer_16x16(inputs)\n","        x = self.relu(x)\n","        x = self.dropout(x, training=training)\n","        x = self.layer_out_16x16(x)\n","        x = self.pool(x)\n","        x = self.sigmoid(x)\n","        \n","        x = x * (fader/self.fader_total)\n","        x = x + old\n","        \n","        x = self.model_8x8(x, training=training)\n","        \n","        return x\n","     \n","    @tf.function   \n","    def model_32x32(self, inputs, fader=500, training=False):\n","        \n","        old = self.pool(inputs) * 1-(fader/self.fader_total)\n","        \n","        x = self.layer_32x32(inputs)\n","        x = self.relu(x)\n","        x = self.dropout(x, training=training)\n","        x = self.layer_out_32x32(x)\n","        x = self.pool(x)\n","        x = self.sigmoid(x)\n","        \n","        x = x * (fader/self.fader_total)\n","        x = x + old\n","        \n","        x = self.model_16x16(x, training=training)\n","        \n","        return x\n","     \n","    @tf.function   \n","    def model_64x64(self, inputs, fader=500, training=False):\n","        \n","        old = self.pool(inputs) * 1-(fader/self.fader_total)\n","        \n","        x = self.layer_64x64(inputs)\n","        x = self.relu(x)\n","        x = self.dropout(x, training=training)\n","        x = self.layer_out_64x64(x)\n","        x = self.pool(x)\n","        x = self.sigmoid(x)\n","        \n","        x = x * (fader/self.fader_total)\n","        x = x + old\n","        \n","        x = self.model_32x32(x, training=training)\n","        \n","        return x\n","     \n","    @tf.function   \n","    def model_128x128(self, inputs, fader=500, training=False):\n","        \n","        old = self.pool(inputs) * 1-(fader/self.fader_total)\n","        \n","        x = self.layer_128x128(inputs)\n","        x = self.relu(x)\n","        x = self.dropout(x, training=training)\n","        x = self.layer_out_128x128(x)\n","        x = self.pool(x)\n","        x = self.sigmoid(x)\n","        \n","        x = x * (fader/self.fader_total)\n","        x = x + old\n","        \n","        x = self.model_64x64(x, training=training)\n","        \n","        return x\n","     \n","    @tf.function   \n","    def model_256x256(self, inputs, fader=500, training=False):\n","        \n","        old = self.pool(inputs) * 1-(fader/self.fader_total)\n","        \n","        x = self.layer_256x256(inputs)\n","        x = self.relu(x)\n","        x = self.dropout(x, training=training)\n","        x = self.layer_out_256x256(x)\n","        x = self.pool(x)\n","        x = self.sigmoid(x)\n","        \n","        x = x * (fader/self.fader_total)\n","        x = x + old\n","        \n","        x = self.model_128x128(x, training=training)\n","        \n","        return x\n","     \n","    @tf.function   \n","    def model_512x512(self, inputs, fader=500, training=False):\n","        \n","        old = self.pool(inputs) * 1-(fader/self.fader_total)\n","        \n","        x = self.layer_512x512(inputs)\n","        x = self.relu(x)\n","        x = self.dropout(x, training=training)\n","        x = self.layer_out_512x512(x)\n","        x = self.pool(x)\n","        x = self.sigmoid(x)\n","        \n","        x = x * (fader/self.fader_total)\n","        x = x + old\n","        \n","        x = self.model_256x256(x, training=training)\n","        \n","        return x\n","        \n","    \n","    \n","    \n","\n","VAE = VAE_model()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["4 (1, 100)\n","8 (1, 100)\n","16 (1, 100)\n","32 (1, 100)\n","64 (1, 100)\n","128 (1, 100)\n","256 (1, 100)\n","512 (1, 100)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YiJor8cCgfF1","colab_type":"code","outputId":"2d896a6f-995d-4b06-b3a0-2657de39c4da","executionInfo":{"status":"ok","timestamp":1562275551698,"user_tz":420,"elapsed":40276,"user":{"displayName":"Michael Jankowiak","photoUrl":"","userId":"13749907316228325380"}},"colab":{"base_uri":"https://localhost:8080/","height":153}},"source":["class generator_model(tf.keras.Model):\n","    @tf.function\n","    def __init__(self):\n","        super(generator_model, self).__init__()\n","        \n","        self.relu = layers.LeakyReLU()\n","        self.sigmoid = layers.Activation('sigmoid')\n","        self.layer_upsample = layers.UpSampling2D()\n","        \n","        self.layer_dense = layers.Dense(4*4*256, use_bias=False, input_shape=(100,))\n","        self.layer_dense_norm = layers.BatchNormalization()\n","        self.reshape_4x4 = layers.Reshape((4, 4, 256))\n","        self.layer_out_4x4 = layers.Conv2D(3, (1, 1), strides=1, padding='same', use_bias=False)\n","        \n","        \n","        self.layer_8x8 = layers.Conv2D(128, (3, 3), strides=1, padding='same', use_bias=False)\n","        self.layer_norm_8x8 = layers.BatchNormalization()\n","        self.layer_out_8x8 = layers.Conv2D(3, (1, 1), strides=1, padding='same', use_bias=False)\n","        \n","\n","        self.layer_16x16 = layers.Conv2D(128, (3, 3), strides=1, padding='same', use_bias=False)\n","        self.layer_norm_16x16 = layers.BatchNormalization()\n","        self.layer_out_16x16 = layers.Conv2D(3, (1, 1), strides=1, padding='same', use_bias=False)\n","        \n","\n","        self.layer_32x32 = layers.Conv2D(64, (3, 3), strides=1, padding='same', use_bias=False)\n","        self.layer_norm_32x32 = layers.BatchNormalization()\n","        self.layer_out_32x32 = layers.Conv2D(3, (1, 1), strides=1, padding='same', use_bias=False)\n","\n","\n","        self.layer_64x64 = layers.Conv2D(64, (3, 3), strides=1, padding='same', use_bias=False)\n","        self.layer_norm_64x64 = layers.BatchNormalization()\n","        self.layer_out_64x64 = layers.Conv2D(3, (1, 1), strides=1, padding='same', use_bias=False)\n","\n","\n","        self.layer_128x128 = layers.Conv2D(32, (3, 3), strides=1, padding='same', use_bias=False)\n","        self.layer_norm_128x128 = layers.BatchNormalization()\n","        self.layer_out_128x128 = layers.Conv2D(3, (1, 1), strides=1, padding='same', use_bias=False)\n","        \n","\n","        self.layer_256x256 = layers.Conv2D(32, (3, 3), strides=1, padding='same', use_bias=False)\n","        self.layer_norm_256x256 = layers.BatchNormalization()\n","        self.layer_out_256x256 = layers.Conv2D(3, (1, 1), strides=1, padding='same', use_bias=False)\n","        \n","\n","        self.layer_512x512 = layers.Conv2D(16, (3, 3), strides=1, padding='same', use_bias=False)\n","        self.layer_norm_512x512 = layers.BatchNormalization()\n","        self.layer_out_512x512 = layers.Conv2D(3, (1, 1), strides=1, padding='same', use_bias=False)\n","        \n","        \n","        self.op = tf.keras.optimizers.Adam(1e-4)\n","        self.fader_total = 500\n","        \n","        \n","        noise = tf.random.normal([1, 100])\n","\n","        output = self.model_4x4(noise)\n","        print(output.shape)\n","\n","        output = self.model_8x8(noise)\n","        print(output.shape)\n","\n","        output = self.model_16x16(noise)\n","        print(output.shape)\n","\n","        output = self.model_32x32(noise)\n","        print(output.shape)\n","\n","        output = self.model_64x64(noise)\n","        print(output.shape)\n","\n","        output = self.model_128x128(noise)\n","        print(output.shape)\n","\n","        output = self.model_256x256(noise)\n","        print(output.shape)\n","\n","        output = self.model_512x512(noise)\n","        print(output.shape)\n","        \n","\n","        self.layer_4x4_vars = self.layer_dense.trainable_weights + self.layer_dense_norm.trainable_weights + self.layer_out_4x4.trainable_weights\n","        self.layer_8x8_vars = self.layer_4x4_vars + self.layer_8x8.trainable_weights + self.layer_norm_8x8.trainable_weights + self.layer_out_8x8.trainable_weights\n","        self.layer_16x16_vars = self.layer_8x8_vars + self.layer_16x16.trainable_weights + self.layer_norm_16x16.trainable_weights + self.layer_out_16x16.trainable_weights\n","        self.layer_32x32_vars = self.layer_16x16_vars + self.layer_32x32.trainable_weights + self.layer_norm_32x32.trainable_weights + self.layer_out_32x32.trainable_weights\n","        self.layer_64x64_vars = self.layer_32x32_vars + self.layer_64x64.trainable_weights + self.layer_norm_64x64.trainable_weights + self.layer_out_64x64.trainable_weights\n","        self.layer_128x128_vars = self.layer_64x64_vars + self.layer_128x128.trainable_weights + self.layer_norm_128x128.trainable_weights + self.layer_out_128x128.trainable_weights\n","        self.layer_256x256_vars = self.layer_128x128_vars + self.layer_256x256.trainable_weights + self.layer_norm_256x256.trainable_weights + self.layer_out_256x256.trainable_weights\n","        self.layer_512x512_vars = self.layer_256x256_vars + self.layer_512x512.trainable_weights + self.layer_norm_512x512.trainable_weights + self.layer_out_512x512.trainable_weights\n","        \n","        \n","    @tf.function\n","    def model_4x4(self, inputs, fader=500, training=False):\n","        x = self.layer_dense(inputs)\n","        x = self.layer_dense_norm(x, training=training)\n","        x = self.relu(x)\n","        x = self.reshape_4x4(x)\n","        x = self.layer_out_4x4(x)\n","        x = self.sigmoid(x)\n","        \n","        return x\n","\n","    @tf.function\n","    def model_8x8(self, inputs, fader=500, training=False):\n","        x = self.model_4x4(inputs, training=training)\n","        x = self.layer_upsample(x)\n","        \n","        old = x * 1-(fader/self.fader_total)\n","        \n","        x = self.layer_8x8(x)\n","        x = self.layer_norm_8x8(x, training=training)\n","        x = self.relu(x)\n","        \n","        x = self.layer_out_8x8(x)\n","        x = self.sigmoid(x)\n","        \n","        x = x * (fader/self.fader_total)\n","        x = x + old\n","        \n","        return x\n","\n","    @tf.function\n","    def model_16x16(self, inputs, fader=500, training=False):\n","        x = self.model_8x8(inputs, training=training)\n","        x = self.layer_upsample(x)\n","        \n","        old = x * 1-(fader/self.fader_total)\n","        \n","        x = self.layer_16x16(x)\n","        x = self.layer_norm_16x16(x, training=training)\n","        x = self.relu(x)\n","        \n","        x = self.layer_out_16x16(x)\n","        x = self.sigmoid(x)\n","        \n","        x = x * (fader/self.fader_total)\n","        x = x + old\n","        \n","        return x\n","\n","    @tf.function\n","    def model_32x32(self, inputs, fader=500, training=False):\n","        x = self.model_16x16(inputs, training=training)\n","        x = self.layer_upsample(x)\n","        \n","        old = x * 1-(fader/self.fader_total)\n","        \n","        x = self.layer_32x32(x)\n","        x = self.layer_norm_32x32(x, training=training)\n","        x = self.relu(x)\n","        \n","        x = self.layer_out_32x32(x)\n","        x = self.sigmoid(x)\n","        \n","        x = x * (fader/self.fader_total)\n","        x = x + old\n","        \n","        return x\n","\n","    @tf.function\n","    def model_64x64(self, inputs, fader=500, training=False):\n","        x = self.model_32x32(inputs, training=training)\n","        x = self.layer_upsample(x)\n","        \n","        old = x * 1-(fader/self.fader_total)\n","        \n","        x = self.layer_64x64(x)\n","        x = self.layer_norm_64x64(x, training=training)\n","        x = self.relu(x)\n","        \n","        x = self.layer_out_64x64(x)\n","        x = self.sigmoid(x)\n","        \n","        x = x * (fader/self.fader_total)\n","        x = x + old\n","        \n","        return x\n","\n","    @tf.function\n","    def model_128x128(self, inputs, fader=500, training=False):\n","        x = self.model_64x64(inputs, training=training)\n","        x = self.layer_upsample(x)\n","        \n","        old = x * 1-(fader/self.fader_total)\n","        \n","        x = self.layer_128x128(x)\n","        x = self.layer_norm_128x128(x, training=training)\n","        x = self.relu(x)\n","        \n","        x = self.layer_out_128x128(x)\n","        x = self.sigmoid(x)\n","        \n","        x = x * (fader/self.fader_total)\n","        x = x + old\n","        \n","        return x\n","\n","    @tf.function\n","    def model_256x256(self, inputs, fader=500, training=False):\n","        x = self.model_128x128(inputs, training=training)\n","        x = self.layer_upsample(x)\n","        \n","        old = x * 1-(fader/self.fader_total)\n","        \n","        x = self.layer_256x256(x)\n","        x = self.layer_norm_256x256(x, training=training)\n","        x = self.relu(x)\n","        \n","        x = self.layer_out_256x256(x)\n","        x = self.sigmoid(x)\n","        \n","        x = x * (fader/self.fader_total)\n","        x = x + old\n","        \n","        return x\n","\n","    @tf.function\n","    def model_512x512(self, inputs, fader=500, training=False):\n","        x = self.model_256x256(inputs, training=training)\n","        x = self.layer_upsample(x)\n","        \n","        old = x * 1-(fader/self.fader_total)\n","        \n","        x = self.layer_512x512(x)\n","        x = self.layer_norm_512x512(x, training=training)\n","        x = self.relu(x)\n","        \n","        x = self.layer_out_512x512(x)\n","        x = self.sigmoid(x)\n","        \n","        x = x * (fader/self.fader_total)\n","        x = x + old\n","        \n","        return x\n","    \n","    \n","\n","generator = generator_model()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(1, 4, 4, 3)\n","(1, 8, 8, 3)\n","(1, 16, 16, 3)\n","(1, 32, 32, 3)\n","(1, 64, 64, 3)\n","(1, 128, 128, 3)\n","(1, 256, 256, 3)\n","(1, 512, 512, 3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"28XJwHopnU33","outputId":"2b51de61-28d0-4d3d-a933-c98b2ee81e12","executionInfo":{"status":"ok","timestamp":1562275556387,"user_tz":420,"elapsed":44956,"user":{"displayName":"Michael Jankowiak","photoUrl":"","userId":"13749907316228325380"}},"colab":{"base_uri":"https://localhost:8080/","height":153}},"source":["class discriminator_model(tf.keras.Model):\n","    @tf.function\n","    def __init__(self):\n","        super(discriminator_model, self).__init__()\n","        \n","        self.relu = layers.LeakyReLU()\n","        self.sigmoid = layers.Activation('sigmoid')\n","        self.dropout = layers.Dropout(0.3)\n","        self.pool = layers.AveragePooling2D(strides=2, padding='same')\n","        self.gaus_noise = layers.GaussianNoise(.5)\n","        \n","        \n","        self.layer_512x512 = layers.Conv2D(16, (3, 3), strides=1, padding='same')\n","        self.layer_out_512x512 = layers.Conv2D(3, 1, strides=1, padding='same')\n","        \n","        \n","        self.layer_256x256 = layers.Conv2D(32, (3, 3), strides=1, padding='same')\n","        self.layer_out_256x256 = layers.Conv2D(3, 1, strides=1, padding='same')\n","        \n","        \n","        self.layer_128x128 = layers.Conv2D(32, (3, 3), strides=1, padding='same')\n","        self.layer_out_128x128 = layers.Conv2D(3, 1, strides=1, padding='same')\n","        \n","        \n","        self.layer_64x64 = layers.Conv2D(64, (3, 3), strides=1, padding='same')\n","        self.layer_out_64x64 = layers.Conv2D(3, 1, strides=1, padding='same')\n","        \n","        \n","        self.layer_32x32 = layers.Conv2D(64, (3, 3), strides=1, padding='same')\n","        self.layer_out_32x32 = layers.Conv2D(3, 1, strides=1, padding='same')\n","        \n","        \n","        self.layer_16x16 = layers.Conv2D(128, (3, 3), strides=1, padding='same')\n","        self.layer_out_16x16 = layers.Conv2D(3, 1, strides=1, padding='same')\n","        \n","        \n","        self.layer_8x8 = layers.Conv2D(128, 3, strides=1, padding='same')\n","        self.layer_out_8x8 = layers.Conv2D(3, 1, strides=1, padding='same')\n","\n","        \n","        self.layer_4x4 = layers.Conv2D(256, 4, strides=1, padding='same', name='layer_4x4')\n","        \n","        \n","        self.flatten = layers.Flatten()\n","        self.layer_out = layers.Dense(1, name='layer_out')\n","        \n","        \n","        self.op = tf.keras.optimizers.Adam(1e-4)\n","        self.fader_total = 500\n","        \n","\n","        noise = self.gaus_noise(tf.random.normal([1, 4, 4, 3]))\n","        output = self.model_4x4(noise)\n","        print(4, output.shape)\n","\n","        noise = self.gaus_noise(tf.random.normal([1, 8, 8, 3]))\n","        output = self.model_8x8(noise)\n","        print(8, output.shape)\n","\n","        noise = self.gaus_noise(tf.random.normal([1, 16, 16, 3]))\n","        output = self.model_16x16(noise)\n","        print(16, output.shape)\n","\n","        noise = self.gaus_noise(tf.random.normal([1, 32, 32, 3]))\n","        output = self.model_32x32(noise)\n","        print(32, output.shape)\n","\n","        noise = self.gaus_noise(tf.random.normal([1, 64, 64, 3]))\n","        output = self.model_64x64(noise)\n","        print(64, output.shape)\n","\n","        noise = self.gaus_noise(tf.random.normal([1, 128, 128, 3]))\n","        output = self.model_128x128(noise)\n","        print(128, output.shape)\n","\n","        noise = self.gaus_noise(tf.random.normal([1, 256, 256, 3]))\n","        output = self.model_256x256(noise)\n","        print(256, output.shape)\n","\n","        noise = self.gaus_noise(tf.random.normal([1, 512, 512, 3]))\n","        output = self.model_512x512(noise)\n","        print(512, output.shape)\n","        \n","        \n","        \n","        self.layer_4x4_vars = self.layer_out.trainable_weights + self.layer_4x4.trainable_weights\n","        self.layer_8x8_vars = self.layer_4x4_vars + self.layer_8x8.trainable_weights + self.layer_out_8x8.trainable_weights\n","        self.layer_16x16_vars  = self.layer_8x8_vars + self.layer_16x16.trainable_weights + self.layer_out_16x16.trainable_weights\n","        self.layer_32x32_vars = self.layer_16x16_vars + self.layer_32x32.trainable_weights + self.layer_out_32x32.trainable_weights\n","        self.layer_64x64_vars = self.layer_32x32_vars + self.layer_64x64.trainable_weights + self.layer_out_64x64.trainable_weights\n","        self.layer_128x128_vars = self.layer_64x64_vars + self.layer_128x128.trainable_weights + self.layer_out_128x128.trainable_weights\n","        self.layer_256x256_vars = self.layer_128x128_vars + self.layer_256x256.trainable_weights + self.layer_out_256x256.trainable_weights\n","        self.layer_512x512_vars = self.layer_256x256_vars + self.layer_512x512.trainable_weights + self.layer_out_512x512.trainable_weights\n","        \n","        \n","    @tf.function\n","    def model_4x4(self, inputs, fader=500, training=False):\n","        x = self.layer_4x4(inputs)\n","        x = self.relu(x)\n","        x = self.dropout(x, training=training)\n","        \n","        x = self.flatten(x)\n","        x = self.layer_out(x)\n","        \n","        return x\n","     \n","    @tf.function   \n","    def model_8x8(self, inputs, fader=500, training=False):\n","        \n","        old = self.pool(inputs) * 1-(fader/self.fader_total)\n","        \n","        x = self.layer_8x8(inputs)\n","        x = self.relu(x)\n","        x = self.dropout(x, training=training)\n","        x = self.layer_out_8x8(x)\n","        x = self.pool(x)\n","        x = self.sigmoid(x)\n","        \n","        x = x * (fader/self.fader_total)\n","        x = x + old\n","        \n","        x = self.model_4x4(x, training=training)\n","        \n","        return x\n","     \n","    @tf.function   \n","    def model_16x16(self, inputs, fader=500, training=False):\n","        \n","        old = self.pool(inputs) * 1-(fader/self.fader_total)\n","        \n","        x = self.layer_16x16(inputs)\n","        x = self.relu(x)\n","        x = self.dropout(x, training=training)\n","        x = self.layer_out_16x16(x)\n","        x = self.pool(x)\n","        x = self.sigmoid(x)\n","        \n","        x = x * (fader/self.fader_total)\n","        x = x + old\n","        \n","        x = self.model_8x8(x, training=training)\n","        \n","        return x\n","     \n","    @tf.function   \n","    def model_32x32(self, inputs, fader=500, training=False):\n","        \n","        old = self.pool(inputs) * 1-(fader/self.fader_total)\n","        \n","        x = self.layer_32x32(inputs)\n","        x = self.relu(x)\n","        x = self.dropout(x, training=training)\n","        x = self.layer_out_32x32(x)\n","        x = self.pool(x)\n","        x = self.sigmoid(x)\n","        \n","        x = x * (fader/self.fader_total)\n","        x = x + old\n","        \n","        x = self.model_16x16(x, training=training)\n","        \n","        return x\n","     \n","    @tf.function   \n","    def model_64x64(self, inputs, fader=500, training=False):\n","        \n","        old = self.pool(inputs) * 1-(fader/self.fader_total)\n","        \n","        x = self.layer_64x64(inputs)\n","        x = self.relu(x)\n","        x = self.dropout(x, training=training)\n","        x = self.layer_out_64x64(x)\n","        x = self.pool(x)\n","        x = self.sigmoid(x)\n","        \n","        x = x * (fader/self.fader_total)\n","        x = x + old\n","        \n","        x = self.model_32x32(x, training=training)\n","        \n","        return x\n","     \n","    @tf.function   \n","    def model_128x128(self, inputs, fader=500, training=False):\n","        \n","        old = self.pool(inputs) * 1-(fader/self.fader_total)\n","        \n","        x = self.layer_128x128(inputs)\n","        x = self.relu(x)\n","        x = self.dropout(x, training=training)\n","        x = self.layer_out_128x128(x)\n","        x = self.pool(x)\n","        x = self.sigmoid(x)\n","        \n","        x = x * (fader/self.fader_total)\n","        x = x + old\n","        \n","        x = self.model_64x64(x, training=training)\n","        \n","        return x\n","     \n","    @tf.function   \n","    def model_256x256(self, inputs, fader=500, training=False):\n","        \n","        old = self.pool(inputs) * 1-(fader/self.fader_total)\n","        \n","        x = self.layer_256x256(inputs)\n","        x = self.relu(x)\n","        x = self.dropout(x, training=training)\n","        x = self.layer_out_256x256(x)\n","        x = self.pool(x)\n","        x = self.sigmoid(x)\n","        \n","        x = x * (fader/self.fader_total)\n","        x = x + old\n","        \n","        x = self.model_128x128(x, training=training)\n","        \n","        return x\n","     \n","    @tf.function   \n","    def model_512x512(self, inputs, fader=500, training=False):\n","        \n","        old = self.pool(inputs) * 1-(fader/self.fader_total)\n","        \n","        x = self.layer_512x512(inputs)\n","        x = self.relu(x)\n","        x = self.dropout(x, training=training)\n","        x = self.layer_out_512x512(x)\n","        x = self.pool(x)\n","        x = self.sigmoid(x)\n","        \n","        x = x * (fader/self.fader_total)\n","        x = x + old\n","        \n","        x = self.model_256x256(x, training=training)\n","        \n","        return x\n","        \n","    \n","    \n","    \n","\n","discriminator = discriminator_model()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["4 (1, 1)\n","8 (1, 1)\n","16 (1, 1)\n","32 (1, 1)\n","64 (1, 1)\n","128 (1, 1)\n","256 (1, 1)\n","512 (1, 1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"eKRGA8CphHkm","colab_type":"code","colab":{}},"source":["cross_entropy_logits = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n","cross_entropy_regulerizer = tf.keras.losses.CategoricalCrossentropy()\n","\n","@tf.function\n","def log_normal_pdf(sample, mean, logvar, raxis=1):\n","    log2pi = tf.math.log(2. * np.pi)\n","    return tf.reduce_sum(\n","        -.5 * ((sample - mean) ** 2. * tf.exp(-logvar) + logvar + log2pi),\n","        axis=raxis)\n","\n","@tf.function\n","def regulerizer_loss(z, mean, logvar, generated_images, images):\n","    logpx_z = cross_entropy_regulerizer(images, generated_images)\n","    logpz = tf.math.reduce_mean(log_normal_pdf(z, 0., 0.))\n","    logqz_x = tf.math.reduce_mean(log_normal_pdf(z, mean, logvar))\n","    return (logpx_z + logpz - logqz_x)\n","\n","@tf.function\n","def discriminator_loss(real_output, fake_output):\n","    real_loss = cross_entropy_logits(tf.ones_like(real_output), real_output)\n","    fake_loss = cross_entropy_logits(tf.zeros_like(fake_output), fake_output)\n","    total_loss = real_loss + fake_loss\n","    return total_loss\n","\n","@tf.function\n","def generator_loss(fake_output):\n","    total_loss = cross_entropy_logits(tf.ones_like(fake_output), fake_output)\n","    return total_loss\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2yvi-hvahmA5","colab_type":"code","outputId":"afa64af2-8d2c-4524-ab80-7523c8b7502e","executionInfo":{"status":"ok","timestamp":1562275556392,"user_tz":420,"elapsed":44943,"user":{"displayName":"Michael Jankowiak","photoUrl":"","userId":"13749907316228325380"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["EPOCHS = 100\n","noise_dim = 100\n","num_examples_to_generate = 49\n","\n","\n","    \n","seed = tf.Variable(tf.random.normal([num_examples_to_generate, noise_dim]))\n","\n","checkpoint_dir = path + folder +'_checkpoints'\n","checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n","checkpoint = tf.train.Checkpoint(seed=seed,\n","                                 step=tf.Variable(0),\n","                                 level=tf.Variable(0),\n","                                 fader=tf.Variable(0, dtype=tf.float32),\n","                                 VAE=VAE,\n","                                 generator=generator,\n","                                 discriminator=discriminator)\n","\n","\n","\n","if continue_training:\n","    checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n","    print(checkpoint.step)\n","    print('Loaded!')\n","else:\n","    try:\n","        os.mkdir(path+folder+'_imgs')\n","    except: pass\n","    try:\n","        os.mkdir(path+folder+'_checkpoints')\n","    except: pass\n","    try:\n","        os.mkdir(path+folder+'_graphs')\n","    except: pass\n","    print(checkpoint.step)\n","    print('New!')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["<tf.Variable 'Variable:0' shape=() dtype=int32, numpy=0>\n","New!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_YVGtS8RaMKJ","colab_type":"code","colab":{}},"source":["@tf.function\n","def train_step_4x4(images):\n","\n","    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n","        \n","        images_with_gaus = images\n","        images_with_gaus = discriminator.gaus_noise(images)\n","        \n","        z, mean, logvar = VAE.model_4x4(images, fader=checkpoint.fader, training=True)\n","        \n","        generated_images = generator.model_4x4(z, fader=checkpoint.fader, training=True)\n","        generated_images_with_gaus = generated_images\n","        generated_images_with_gaus = discriminator.gaus_noise(generated_images)\n","\n","        \n","        real_output = discriminator.model_4x4(images_with_gaus, fader=checkpoint.fader, training=True)\n","        fake_output = discriminator.model_4x4(generated_images_with_gaus, fader=checkpoint.fader, training=True)\n","        \n","        \n","        reg_loss = regulerizer_loss(z, mean, logvar, generated_images_with_gaus, images)\n","        gen_loss = generator_loss(fake_output)\n","        total_gen_loss = gen_loss - (0.1*reg_loss)\n","        disc_loss = discriminator_loss(real_output, fake_output)\n","\n","    gradients_of_generator = gen_tape.gradient(total_gen_loss, generator.layer_4x4_vars+VAE.layer_4x4_vars)\n","    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.layer_4x4_vars)\n","\n","    generator.op.apply_gradients(zip(gradients_of_generator, generator.layer_4x4_vars+VAE.layer_4x4_vars))\n","    discriminator.op.apply_gradients(zip(gradients_of_discriminator, discriminator.layer_4x4_vars))\n","    \n","    return gen_loss, disc_loss\n","    \n","    \n","@tf.function\n","def train_step_8x8(images):\n","\n","    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n","        \n","        images_with_gaus = images\n","        images_with_gaus = discriminator.gaus_noise(images)\n","        \n","        z, mean, logvar = VAE.model_8x8(images, fader=checkpoint.fader, training=True)\n","        \n","        generated_images = generator.model_8x8(z, fader=checkpoint.fader, training=True)\n","        generated_images_with_gaus = generated_images\n","        generated_images_with_gaus = discriminator.gaus_noise(generated_images)\n","\n","        \n","        real_output = discriminator.model_8x8(images_with_gaus, fader=checkpoint.fader, training=True)\n","        fake_output = discriminator.model_8x8(generated_images_with_gaus, fader=checkpoint.fader, training=True)\n","        \n","        \n","        reg_loss = regulerizer_loss(z, mean, logvar, generated_images_with_gaus, images)\n","        gen_loss = generator_loss(fake_output)\n","        total_gen_loss = gen_loss - (0.1*reg_loss)\n","        disc_loss = discriminator_loss(real_output, fake_output)\n","\n","    gradients_of_generator = gen_tape.gradient(total_gen_loss, generator.layer_8x8_vars+VAE.layer_8x8_vars)\n","    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.layer_8x8_vars)\n","\n","    generator.op.apply_gradients(zip(gradients_of_generator, generator.layer_8x8_vars+VAE.layer_8x8_vars))\n","    discriminator.op.apply_gradients(zip(gradients_of_discriminator, discriminator.layer_8x8_vars))\n","    \n","    return gen_loss, disc_loss\n","    \n","    \n","@tf.function\n","def train_step_16x16(images):\n","\n","    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n","        \n","        images_with_gaus = images\n","        images_with_gaus = discriminator.gaus_noise(images)\n","        \n","        z, mean, logvar = VAE.model_16x16(images, fader=checkpoint.fader, training=True)\n","        \n","        generated_images = generator.model_16x16(z, fader=checkpoint.fader, training=True)\n","        generated_images_with_gaus = generated_images\n","        generated_images_with_gaus = discriminator.gaus_noise(generated_images)\n","\n","        \n","        real_output = discriminator.model_16x16(images_with_gaus, fader=checkpoint.fader, training=True)\n","        fake_output = discriminator.model_16x16(generated_images_with_gaus, fader=checkpoint.fader, training=True)\n","        \n","        \n","        reg_loss = regulerizer_loss(z, mean, logvar, generated_images_with_gaus, images)\n","        gen_loss = generator_loss(fake_output)\n","        total_gen_loss = gen_loss - (0.1*reg_loss)\n","        disc_loss = discriminator_loss(real_output, fake_output)\n","\n","    gradients_of_generator = gen_tape.gradient(total_gen_loss, generator.layer_16x16_vars+VAE.layer_16x16_vars)\n","    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.layer_16x16_vars)\n","\n","    generator.op.apply_gradients(zip(gradients_of_generator, generator.layer_16x16_vars+VAE.layer_16x16_vars))\n","    discriminator.op.apply_gradients(zip(gradients_of_discriminator, discriminator.layer_16x16_vars))\n","    \n","    return gen_loss, disc_loss\n","    \n","    \n","@tf.function\n","def train_step_32x32(images):\n","    noise = tf.random.normal([images.shape[0], noise_dim])\n","\n","    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n","        \n","        images_with_gaus = images\n","        images_with_gaus = discriminator.gaus_noise(images)\n","        \n","        z, mean, logvar = VAE.model_32x32(images, fader=checkpoint.fader, training=True)\n","        \n","        generated_images = generator.model_32x32(z, fader=checkpoint.fader, training=True)\n","        generated_images_with_gaus = generated_images\n","        generated_images_with_gaus = discriminator.gaus_noise(generated_images)\n","\n","        \n","        real_output = discriminator.model_32x32(images_with_gaus, fader=checkpoint.fader, training=True)\n","        fake_output = discriminator.model_32x32(generated_images_with_gaus, fader=checkpoint.fader, training=True)\n","        \n","        \n","        reg_loss = regulerizer_loss(z, mean, logvar, generated_images_with_gaus, images)\n","        gen_loss = generator_loss(fake_output)\n","        total_gen_loss = gen_loss - (0.1*reg_loss)\n","        disc_loss = discriminator_loss(real_output, fake_output)\n","\n","    gradients_of_generator = gen_tape.gradient(total_gen_loss, generator.layer_32x32_vars+VAE.layer_32x32_vars)\n","    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.layer_32x32_vars)\n","\n","    generator.op.apply_gradients(zip(gradients_of_generator, generator.layer_32x32_vars+VAE.layer_32x32_vars))\n","    discriminator.op.apply_gradients(zip(gradients_of_discriminator, discriminator.layer_32x32_vars))\n","    \n","    return gen_loss, disc_loss\n","    \n","    \n","@tf.function\n","def train_step_64x64(images):\n","\n","    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n","        \n","        images_with_gaus = discriminator.gaus_noise(images)\n","        \n","        z, mean, logvar = VAE.model_64x64(images, fader=checkpoint.fader, training=True)\n","        \n","        generated_images = generator.model_64x64(z, fader=checkpoint.fader, training=True)\n","        generated_images_with_gaus = discriminator.gaus_noise(generated_images)\n","\n","        \n","        real_output = discriminator.model_64x64(images_with_gaus, fader=checkpoint.fader, training=True)\n","        fake_output = discriminator.model_64x64(generated_images_with_gaus, fader=checkpoint.fader, training=True)\n","        \n","        \n","        reg_loss = regulerizer_loss(z, mean, logvar, generated_images_with_gaus, images)\n","        gen_loss = generator_loss(fake_output)\n","        total_gen_loss = gen_loss - (0.1*reg_loss)\n","        disc_loss = discriminator_loss(real_output, fake_output)\n","\n","    gradients_of_generator = gen_tape.gradient(total_gen_loss, generator.layer_64x64_vars+VAE.layer_64x64_vars)\n","    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.layer_64x64_vars)\n","\n","    generator.op.apply_gradients(zip(gradients_of_generator, generator.layer_64x64_vars+VAE.layer_64x64_vars))\n","    discriminator.op.apply_gradients(zip(gradients_of_discriminator, discriminator.layer_64x64_vars))\n","    \n","    return gen_loss, disc_loss\n","    \n","    \n","@tf.function\n","def train_step_128x128(images):\n","\n","    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n","        \n","        images_with_gaus = discriminator.gaus_noise(images)\n","        \n","        z, mean, logvar = VAE.model_128x128(images, fader=checkpoint.fader, training=True)\n","        \n","        generated_images = generator.model_128x128(z, fader=checkpoint.fader, training=True)\n","        generated_images_with_gaus = discriminator.gaus_noise(generated_images)\n","\n","        \n","        real_output = discriminator.model_128x128(images_with_gaus, fader=checkpoint.fader, training=True)\n","        fake_output = discriminator.model_128x128(generated_images_with_gaus, fader=checkpoint.fader, training=True)\n","        \n","        \n","        reg_loss = regulerizer_loss(z, mean, logvar, generated_images_with_gaus, images)\n","        gen_loss = generator_loss(fake_output)\n","        total_gen_loss = gen_loss - (0.1*reg_loss)\n","        disc_loss = discriminator_loss(real_output, fake_output)\n","\n","    gradients_of_generator = gen_tape.gradient(total_gen_loss, generator.layer_128x128_vars+VAE.layer_128x128_vars)\n","    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.layer_128x128_vars)\n","\n","    generator.op.apply_gradients(zip(gradients_of_generator, generator.layer_128x128_vars+VAE.layer_128x128_vars))\n","    discriminator.op.apply_gradients(zip(gradients_of_discriminator, discriminator.layer_128x128_vars))\n","    \n","    return gen_loss, disc_loss\n","    \n","    \n","@tf.function\n","def train_step_256x256(images):\n","    noise = tf.random.normal([images.shape[0], noise_dim])\n","\n","    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n","        \n","        images_with_gaus = discriminator.gaus_noise(images)\n","        \n","        z, mean, logvar = VAE.model_256x256(images, fader=checkpoint.fader, training=True)\n","        \n","        generated_images = generator.model_256x256(z, fader=checkpoint.fader, training=True)\n","        generated_images_with_gaus = discriminator.gaus_noise(generated_images)\n","\n","        \n","        real_output = discriminator.model_256x256(images_with_gaus, fader=checkpoint.fader, training=True)\n","        fake_output = discriminator.model_256x256(generated_images_with_gaus, fader=checkpoint.fader, training=True)\n","        \n","        \n","        reg_loss = regulerizer_loss(z, mean, logvar, generated_images_with_gaus, images)\n","        gen_loss = generator_loss(fake_output)\n","        total_gen_loss = gen_loss - (0.1*reg_loss)\n","        disc_loss = discriminator_loss(real_output, fake_output)\n","\n","    gradients_of_generator = gen_tape.gradient(total_gen_loss, generator.layer_256x256_vars+VAE.layer_256x256_vars)\n","    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.layer_256x256_vars)\n","\n","    generator.op.apply_gradients(zip(gradients_of_generator, generator.layer_256x256_vars+VAE.layer_256x256_vars))\n","    discriminator.op.apply_gradients(zip(gradients_of_discriminator, discriminator.layer_256x256_vars))\n","    \n","    return gen_loss, disc_loss\n","    \n","    \n","@tf.function\n","def train_step_512x512(images):\n","\n","    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n","        \n","        images_with_gaus = discriminator.gaus_noise(images)\n","        \n","        z, mean, logvar = VAE.model_512x512(images, fader=checkpoint.fader, training=True)\n","        \n","        generated_images = generator.model_512x512(z, fader=checkpoint.fader, training=True)\n","        generated_images_with_gaus = discriminator.gaus_noise(generated_images)\n","\n","        \n","        real_output = discriminator.model_512x512(images_with_gaus, fader=checkpoint.fader, training=True)\n","        fake_output = discriminator.model_512x512(generated_images_with_gaus, fader=checkpoint.fader, training=True)\n","        \n","        \n","        reg_loss = regulerizer_loss(z, mean, logvar, generated_images_with_gaus, images)\n","        gen_loss = generator_loss(fake_output)\n","        total_gen_loss = gen_loss - (0.1*reg_loss)\n","        disc_loss = discriminator_loss(real_output, fake_output)\n","\n","    gradients_of_generator = gen_tape.gradient(total_gen_loss, generator.layer_512x512_vars+VAE.layer_512x512_vars)\n","    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.layer_512x512_vars)\n","\n","    generator.op.apply_gradients(zip(gradients_of_generator, generator.layer_512x512_vars+VAE.layer_512x512_vars))\n","    discriminator.op.apply_gradients(zip(gradients_of_discriminator, discriminator.layer_512x512_vars))\n","    \n","    return gen_loss, disc_loss\n","    \n","    \n","# @tf.function\n","# def train_step(images, VAE_model, Gen_model, Dis_model):\n","#     noise = tf.random.normal([images.shape[0], noise_dim])\n","\n","#     with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n","        \n","#         images_with_gaus = discriminator.gaus_noise(images)\n","        \n","#         z, mean, logvar = VAE_model(images, fader=checkpoint.fader, training=True)\n","        \n","#         generated_images = Gen_model(z, fader=checkpoint.fader, training=True)\n","#         generated_images_with_gaus = discriminator.gaus_noise(generated_images)\n","\n","        \n","#         real_output = Dis_model(images_with_gaus, fader=checkpoint.fader, training=True)\n","#         fake_output = Dis_model(generated_images_with_gaus, fader=checkpoint.fader, training=True)\n","        \n","        \n","#         reg_loss = regulerizer_loss(z, mean, logvar, generated_images_with_gaus, images)\n","#         gen_loss = generator_loss(fake_output)\n","#         disc_loss = discriminator_loss(real_output, fake_output)\n","\n","#     gradients_of_generator = gen_tape.gradient(total_gen_loss, generator.trainable_variables+VAE.trainable_variables)\n","#     gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n","\n","#     generator.op.apply_gradients(zip(gradients_of_generator, generator.trainable_variables+VAE.trainable_variables))\n","#     discriminator.op.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n","    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OUKl8bb7hq5d","colab_type":"code","colab":{}},"source":["def train(base_epochs=2000, base_batchs=128):\n","    growing_model = [   (train_step_4x4, generator.model_4x4, 4, int(base_batchs/(2**0)), base_epochs),\n","                            (train_step_8x8, generator.model_8x8, 8, int(base_batchs/(2**0)), base_epochs),\n","                            (train_step_16x16, generator.model_16x16, 16, int(base_batchs/(2**0)), base_epochs),\n","                            (train_step_32x32, generator.model_32x32, 32, int(base_batchs/(2**0)), base_epochs),\n","                            (train_step_64x64, generator.model_64x64, 64, int(base_batchs/(2**0)), base_epochs),\n","                            (train_step_128x128, generator.model_128x128, 128, int(base_batchs/(2**1)), base_epochs),\n","                            (train_step_256x256, generator.model_256x256, 256, int(base_batchs/(2**2)), base_epochs)]#,\n","    #                         (train_step_512x512, generator.model_512x512, 512, int(base_batchs/(2**5)), base_epochs)   ]\n","\n","    for i in range(checkpoint.level.numpy(), len(growing_model)):\n","        (train_step, Gen_model, size, batch_size, epochs) = growing_model[i]\n","        \n","        train_dataset = resize(imgs, size, batch_size)\n","        \n","        discriminate_loss_list = deque(maxlen=500)\n","        generate_loss_list = deque(maxlen=500)\n","        \n","        for epoch in range(checkpoint.step.numpy(), epochs+1):\n","            start = time.time()\n","            gen_epoch_loss = []\n","            disc_epoch_loss = []\n","            \n","            if epoch < generator.fader_total:\n","                checkpoint.fader.assign(epoch)\n","            elif checkpoint.fader != generator.fader_total:\n","                checkpoint.fader.assign(generator.fader_total)\n","\n","\n","            for image_batch in train_dataset:\n","                gen_loss, disc_loss = train_step(image_batch)\n","                gen_epoch_loss.append(gen_loss)\n","                disc_epoch_loss.append(disc_loss)\n","                \n","            discriminate_loss_list.append(tf.reduce_mean(disc_epoch_loss))\n","            generate_loss_list.append(tf.reduce_mean(gen_epoch_loss))\n","            \n","            if (epoch) % 15 == 0:\n","                checkpoint.step.assign(epoch)\n","                checkpoint.level.assign(i)\n","                checkpoint.save(file_prefix = checkpoint_prefix)\n","                generate_and_save_images(Gen_model, size, epoch, seed)\n","                plot_graph_disc_and_gan(discriminate_loss_list, generate_loss_list, size)\n","                \n","                \n","            print ('Time for layer {}, epoch {}, fader {:.1f}% is {:.5f} sec'.format(size, epoch, (checkpoint.fader.numpy()/generator.fader_total)*100, time.time()-start))\n","        del train_dataset\n","        \n","        checkpoint.step.assign(0)\n","        checkpoint.level.assign(i+1)\n","        checkpoint.save(file_prefix = checkpoint_prefix)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UofzdJEei1K1","colab_type":"code","colab":{}},"source":["def generate_and_save_images(model, layer, epoch, test_input):\n","    \n","    display.clear_output(wait=True)\n","    \n","    predictions = model(test_input, training=False)\n","    print(predictions.shape)\n","\n","    fig = plt.figure(1, figsize=(7,7))\n","    plt.clf()\n","\n","    for i in range(predictions.shape[0]):\n","        plt.subplot(7, 7, i+1)\n","        plt.imshow(predictions[i, :, :, :].numpy())\n","        plt.axis('off')\n","\n","    plt.savefig(path+folder+'_imgs/image_{:01d}x{:01d}_{:04d}.png'.format(layer, layer, epoch))\n","    plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AJrU2_aeuZPV","colab_type":"code","colab":{}},"source":["def plot_graph_disc_and_gan(discriminate_loss_list, generate_loss_list, layer):\n","    plt.figure(2)\n","    plt.clf()\n","#     plt.ylim(top=1, bottom=0)\n","    plt.plot(generate_loss_list, c='g')\n","    plt.plot(discriminate_loss_list, c='r')\n","    plt.savefig(path+folder+'_graphs/image_{:01d}x{:01d}.png'.format(layer, layer))\n","    plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gb9H_mR6KtCN","colab_type":"code","outputId":"1b355465-2aab-4822-f669-fc7ddcd64b19","executionInfo":{"status":"error","timestamp":1562277295763,"user_tz":420,"elapsed":3016,"user":{"displayName":"Michael Jankowiak","photoUrl":"","userId":"13749907316228325380"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["train()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["W0704 21:54:54.960684 140146758866816 image.py:648] Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","W0704 21:54:54.980676 140146758866816 image.py:648] Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","W0704 21:54:55.000901 140146758866816 image.py:648] Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","W0704 21:54:55.017400 140146758866816 image.py:648] Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","W0704 21:54:55.037461 140146758866816 image.py:648] Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","W0704 21:54:55.056159 140146758866816 image.py:648] Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","W0704 21:54:55.089779 140146758866816 image.py:648] Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","W0704 21:54:55.111947 140146758866816 image.py:648] Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","W0704 21:54:55.130200 140146758866816 image.py:648] Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"],"name":"stderr"},{"output_type":"stream","text":["(49, 16, 16, 3)\n"],"name":"stdout"},{"output_type":"stream","text":["W0704 21:54:55.152523 140146758866816 image.py:648] Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","W0704 21:54:55.174137 140146758866816 image.py:648] Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","W0704 21:54:55.193286 140146758866816 image.py:648] Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","W0704 21:54:55.213234 140146758866816 image.py:648] Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","W0704 21:54:55.234829 140146758866816 image.py:648] Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","W0704 21:54:55.254264 140146758866816 image.py:648] Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","W0704 21:54:55.275118 140146758866816 image.py:648] Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","W0704 21:54:55.291311 140146758866816 image.py:648] Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","W0704 21:54:55.312554 140146758866816 image.py:648] Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","W0704 21:54:55.333614 140146758866816 image.py:648] Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","W0704 21:54:55.349414 140146758866816 image.py:648] Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","W0704 21:54:55.374054 140146758866816 image.py:648] Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","W0704 21:54:55.396070 140146758866816 image.py:648] Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","W0704 21:54:55.417137 140146758866816 image.py:648] Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","W0704 21:54:55.439829 140146758866816 image.py:648] Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","W0704 21:54:55.459841 140146758866816 image.py:648] Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","W0704 21:54:55.479595 140146758866816 image.py:648] Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","W0704 21:54:55.505715 140146758866816 image.py:648] Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","W0704 21:54:55.526409 140146758866816 image.py:648] Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","W0704 21:54:55.553849 140146758866816 image.py:648] Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","W0704 21:54:55.575148 140146758866816 image.py:648] Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","W0704 21:54:55.596502 140146758866816 image.py:648] Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","W0704 21:54:55.615435 140146758866816 image.py:648] Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","W0704 21:54:55.636109 140146758866816 image.py:648] Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","W0704 21:54:55.655312 140146758866816 image.py:648] Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","W0704 21:54:55.675093 140146758866816 image.py:648] Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","W0704 21:54:55.694684 140146758866816 image.py:648] Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","W0704 21:54:55.711942 140146758866816 image.py:648] Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","W0704 21:54:55.730159 140146758866816 image.py:648] Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","W0704 21:54:55.748730 140146758866816 image.py:648] Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","W0704 21:54:55.767608 140146758866816 image.py:648] Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","W0704 21:54:55.788001 140146758866816 image.py:648] Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","W0704 21:54:55.806230 140146758866816 image.py:648] Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","W0704 21:54:55.824551 140146758866816 image.py:648] Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","W0704 21:54:55.847501 140146758866816 image.py:648] Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","W0704 21:54:55.868938 140146758866816 image.py:648] Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","W0704 21:54:55.888770 140146758866816 image.py:648] Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","W0704 21:54:55.908035 140146758866816 image.py:648] Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","W0704 21:54:55.929538 140146758866816 image.py:648] Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","W0704 21:54:55.946896 140146758866816 image.py:648] Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"],"name":"stderr"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-2da0ffaf5447>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-15-7eeb725c9235>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(base_epochs, base_batchs)\u001b[0m\n\u001b[1;32m     40\u001b[0m                 \u001b[0mcheckpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m                 \u001b[0mcheckpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_prefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpoint_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m                 \u001b[0mgenerate_and_save_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGen_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m                 \u001b[0mplot_graph_disc_and_gan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiscriminate_loss_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerate_loss_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-14-c02581993b2d>\u001b[0m in \u001b[0;36mgenerate_and_save_images\u001b[0;34m(model, layer, epoch, test_input)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_imgs/image_{:01d}x{:01d}_{:04d}.png'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    252\u001b[0m     \"\"\"\n\u001b[1;32m    253\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0m_show\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_show\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/pylab/backend_inline.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(close, block)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfigure_manager\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mGcf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_all_fig_managers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mshow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_to_draw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mdisplay\u001b[0;34m(*objs, **kwargs)\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0mpublish_display_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m             \u001b[0mformat_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mformat_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m                 \u001b[0;31m# nothing to display (e.g. _ipython_display_ took over)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mformat\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0mmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m                 \u001b[0;31m# FIXME: log the exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m</usr/local/lib/python3.6/dist-packages/decorator.py:decorator-gen-9>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mcatch_format_error\u001b[0;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"show traceback on failed format call\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;31m# don't warn on NotImplementedErrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    332\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'png'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'retina'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'png2x'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mretina_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0mbytes_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m   2051\u001b[0m                     \u001b[0mbbox_artists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bbox_extra_artists\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2052\u001b[0m                     bbox_inches = self.figure.get_tightbbox(renderer,\n\u001b[0;32m-> 2053\u001b[0;31m                             bbox_extra_artists=bbox_artists)\n\u001b[0m\u001b[1;32m   2054\u001b[0m                     \u001b[0mpad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pad_inches\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2055\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mpad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36mget_tightbbox\u001b[0;34m(self, renderer, bbox_extra_artists)\u001b[0m\n\u001b[1;32m   2278\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2279\u001b[0m                     bbox = ax.get_tightbbox(renderer,\n\u001b[0;32m-> 2280\u001b[0;31m                             bbox_extra_artists=bbox_extra_artists)\n\u001b[0m\u001b[1;32m   2281\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2282\u001b[0m                     \u001b[0mbbox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tightbbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mget_tightbbox\u001b[0;34m(self, renderer, call_axes_locator, bbox_extra_artists)\u001b[0m\n\u001b[1;32m   4385\u001b[0m             \u001b[0mbb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_right_title\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_window_extent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4387\u001b[0;31m         \u001b[0mbb_yaxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myaxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tightbbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4388\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbb_yaxis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4389\u001b[0m             \u001b[0mbb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbb_yaxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mget_tightbbox\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   1140\u001b[0m         \u001b[0mticks_to_draw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1142\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_label_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m         \u001b[0;31m# go back to just this axis's tick labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m_update_label_position\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   2305\u001b[0m         \u001b[0;31m# get bounding boxes for this axis and any siblings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2306\u001b[0m         \u001b[0;31m# that have been set by `fig.align_ylabels()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2307\u001b[0;31m         \u001b[0mbboxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbboxes2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tick_boxes_siblings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2309\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m_get_tick_boxes_siblings\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   2289\u001b[0m         \u001b[0;31m# if we want to align labels from other axes:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2290\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_siblings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2291\u001b[0;31m             \u001b[0mticks_to_draw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myaxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2292\u001b[0m             \u001b[0mtlb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtlb2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myaxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tick_bboxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticks_to_draw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2293\u001b[0m             \u001b[0mbboxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtlb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m_update_ticks\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   1021\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m         \u001b[0minterval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_view_interval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1023\u001b[0;31m         \u001b[0mtick_tups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# iter_ticks calls the locator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1024\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_smart_bounds\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtick_tups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m             \u001b[0;31m# handle inverted limits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36miter_ticks\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    965\u001b[0m         \u001b[0mIterate\u001b[0m \u001b[0mthrough\u001b[0m \u001b[0mall\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmajor\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mminor\u001b[0m \u001b[0mticks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m         \"\"\"\n\u001b[0;32m--> 967\u001b[0;31m         \u001b[0mmajorLocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmajor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    968\u001b[0m         \u001b[0mmajorTicks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_major_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmajorLocs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmajor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_locs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmajorLocs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/ticker.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1983\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1984\u001b[0m         \u001b[0mvmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_view_interval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1985\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtick_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1987\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtick_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/ticker.py\u001b[0m in \u001b[0;36mtick_values\u001b[0;34m(self, vmin, vmax)\u001b[0m\n\u001b[1;32m   1991\u001b[0m         vmin, vmax = mtransforms.nonsingular(\n\u001b[1;32m   1992\u001b[0m             vmin, vmax, expander=1e-13, tiny=1e-14)\n\u001b[0;32m-> 1993\u001b[0;31m         \u001b[0mlocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raw_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1994\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1995\u001b[0m         \u001b[0mprune\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prune\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/ticker.py\u001b[0m in \u001b[0;36m_raw_ticks\u001b[0;34m(self, vmin, vmax)\u001b[0m\n\u001b[1;32m   1930\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nbins\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'auto'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1931\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1932\u001b[0;31m                 nbins = np.clip(self.axis.get_tick_space(),\n\u001b[0m\u001b[1;32m   1933\u001b[0m                                 max(1, self._min_n_ticks - 1), 9)\n\u001b[1;32m   1934\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mget_tick_space\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2537\u001b[0m         \u001b[0mends\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransAxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2538\u001b[0m         \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mends\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mends\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdpi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m72\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2539\u001b[0;31m         \u001b[0mtick\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2540\u001b[0m         \u001b[0;31m# Having a spacing of at least 2 just looks good.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2541\u001b[0m         \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtick\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m_get_tick\u001b[0;34m(self, major)\u001b[0m\n\u001b[1;32m   2192\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2193\u001b[0m             \u001b[0mtick_kw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_minor_tick_kw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2194\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mYTick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmajor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmajor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtick_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2196\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, axes, loc, label, size, width, color, tickdir, pad, labelsize, labelcolor, zorder, gridOn, tick1On, tick2On, label1On, label2On, major, labelrotation, grid_color, grid_linestyle, grid_linewidth, grid_alpha, **kw)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmajor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m                 \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrcParams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'%s.major.size'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m                 \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrcParams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'%s.minor.size'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    892\u001b[0m                 \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswitch_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrcsetup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_auto_backend_sentinel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"DQGMi1SugN0d","colab_type":"code","colab":{}},"source":["predictions = generator.model_16x16(tf.random.normal([1,noise_dim]), training=False)\n","print(predictions[0].shape)\n","plt.imshow(predictions[0].numpy())\n","plt.show()"],"execution_count":0,"outputs":[]}]}
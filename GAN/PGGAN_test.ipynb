{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"PGGAN_test.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"50r63IyuEOi9","colab_type":"code","outputId":"77d835d4-6fb7-4220-86a4-2ba3d9149cc9","executionInfo":{"status":"ok","timestamp":1562782297756,"user_tz":420,"elapsed":20009,"user":{"displayName":"Michael Jankowiak","photoUrl":"","userId":"13749907316228325380"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["print('Continue?(1=YES/0=NO)')\n","continue_training=bool(int(input()))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Continue?(1=YES/0=NO)\n","0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yfNyBoWsddhp","colab_type":"code","outputId":"47ebec6c-1a7b-4b49-f9e5-8432277922d9","executionInfo":{"status":"ok","timestamp":1562782303562,"user_tz":420,"elapsed":25795,"user":{"displayName":"Michael Jankowiak","photoUrl":"","userId":"13749907316228325380"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["from __future__ import absolute_import, division, print_function, unicode_literals\n","!pip install -q tensorflow-gpu==2.0.0-beta1\n","# import logging\n","# logging.getLogger('tensorflow').disabled = True\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","import numpy as np\n","import cv2\n","import random\n","import time\n","import shutil, os\n","from collections import deque\n","from tensorflow.keras import layers, initializers\n","\n","from IPython import display\n","from tqdm import tqdm\n","\n","# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n","\n","from google.colab import drive\n","drive.mount('/gdrive')\n","path = \"/gdrive/My Drive/GAN/\"\n","folder = \"PGGAN/PGGAN_test\""],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lLRM7t1wfe6I","colab_type":"code","outputId":"d4975308-3a3a-4663-9a18-197a9217d613","executionInfo":{"status":"ok","timestamp":1562782321426,"user_tz":420,"elapsed":43641,"user":{"displayName":"Michael Jankowiak","photoUrl":"","userId":"13749907316228325380"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["imgs = []\n","files = os.listdir(path+\"pokemon/\")\n","random.shuffle(files)\n","file_range = 10 if len(files)-1 > 4000 else len(files)-1\n","for i in tqdm(range(0, file_range)):\n","    img = mpimg.imread(path+\"pokemon/\"+str(files[i]))\n","    imgs.append(img)\n","\n","def resize(images, size, BATCH_SIZE):\n","    i_list = []\n","#     for i in tqdm(images):\n","    for i in images:\n","        i = cv2.resize(i, (size, size), interpolation = cv2.INTER_AREA)\n","        i_list.append(i)\n","\n","\n","    train_images = np.array(i_list).astype('float32')\n","    train_images = train_images / 255\n","    BUFFER_SIZE = 60000\n","    train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n","    return train_dataset"],"execution_count":0,"outputs":[{"output_type":"stream","text":["100%|██████████| 868/868 [00:18<00:00, 47.06it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"Hp03skL805pn","colab_type":"code","outputId":"95ca5133-a17e-4f38-ac82-264dadc7ca98","executionInfo":{"status":"ok","timestamp":1562782330974,"user_tz":420,"elapsed":53175,"user":{"displayName":"Michael Jankowiak","photoUrl":"","userId":"13749907316228325380"}},"colab":{"base_uri":"https://localhost:8080/","height":153}},"source":["class VAE_model(tf.keras.Model):\n","    @tf.function\n","    def __init__(self):\n","        super(VAE_model, self).__init__()\n","        \n","        \n","        self.relu = layers.LeakyReLU()\n","        self.pool = layers.AveragePooling2D(strides=2, padding='same')\n","        \n","        \n","        self.layer_input_512x512 = layers.Conv2D(16, (1, 1), strides=1, padding='same', kernel_initializer=initializers.he_normal())\n","        self.layer_512x512 = layers.Conv2D(16, (3, 3), strides=1, padding='same', kernel_initializer=initializers.he_normal())\n","        \n","        \n","        self.layer_input_256x256 = layers.Conv2D(16, (1, 1), strides=1, padding='same', kernel_initializer=initializers.he_normal())\n","        self.layer_256x256 = layers.Conv2D(32, (3, 3), strides=1, padding='same', kernel_initializer=initializers.he_normal())\n","        \n","        \n","        self.layer_input_128x128 = layers.Conv2D(32, (1, 1), strides=1, padding='same', kernel_initializer=initializers.he_normal())\n","        self.layer_128x128 = layers.Conv2D(32, (3, 3), strides=1, padding='same', kernel_initializer=initializers.he_normal())\n","        \n","        \n","        self.layer_input_64x64 = layers.Conv2D(32, (1, 1), strides=1, padding='same', kernel_initializer=initializers.he_normal())\n","        self.layer_64x64 = layers.Conv2D(64, (3, 3), strides=1, padding='same', kernel_initializer=initializers.he_normal())\n","        \n","        \n","        self.layer_input_32x32 = layers.Conv2D(64, (1, 1), strides=1, padding='same', kernel_initializer=initializers.he_normal())\n","        self.layer_32x32 = layers.Conv2D(64, (3, 3), strides=1, padding='same', kernel_initializer=initializers.he_normal())\n","        \n","        \n","        self.layer_input_16x16 = layers.Conv2D(64, (1, 1), strides=1, padding='same', kernel_initializer=initializers.he_normal())\n","        self.layer_16x16 = layers.Conv2D(128, (3, 3), strides=1, padding='same', kernel_initializer=initializers.he_normal())\n","        \n","        \n","        self.layer_input_8x8 = layers.Conv2D(128, (1, 1), strides=1, padding='same', kernel_initializer=initializers.he_normal())\n","        self.layer_8x8 = layers.Conv2D(128, (3, 3), strides=1, padding='same', kernel_initializer=initializers.he_normal())\n","        \n","        \n","        self.layer_input_4x4 = layers.Conv2D(128, (1, 1), strides=1, padding='same', name='layer_input_4x4')\n","        self.layer_4x4 = layers.Conv2D(256, 4, strides=1, padding='same', name='layer_4x4')\n","        \n","        \n","        self.flatten = layers.Flatten()\n","        self.layer_out = layers.Dense(200)\n","        \n","        \n","        self.fader_total = 500\n","        self.fader = self.fader_total - 1\n","        \n","        \n","        \n","\n","        noise = tf.random.normal([1, 4, 4, 3])\n","        output = self.model_4x4(noise)\n","        print(4, output[0].shape)\n","\n","        noise = tf.random.normal([1, 8, 8, 3])\n","        output = self.model_8x8(noise)\n","        print(8, output[0].shape)\n","\n","        noise = tf.random.normal([1, 16, 16, 3])\n","        output = self.model_16x16(noise)\n","        print(16, output[0].shape)\n","\n","        noise = tf.random.normal([1, 32, 32, 3])\n","        output = self.model_32x32(noise)\n","        print(32, output[0].shape)\n","\n","        noise = tf.random.normal([1, 64, 64, 3])\n","        output = self.model_64x64(noise)\n","        print(64, output[0].shape)\n","\n","        noise = tf.random.normal([1, 128, 128, 3])\n","        output = self.model_128x128(noise)\n","        print(128, output[0].shape)\n","\n","        noise = tf.random.normal([1, 256, 256, 3])\n","        output = self.model_256x256(noise)\n","        print(256, output[0].shape)\n","\n","        noise = tf.random.normal([1, 512, 512, 3])\n","        output = self.model_512x512(noise)\n","        print(512, output[0].shape)\n","        \n","        \n","        self.layer_4x4_vars_main = self.layer_out.trainable_weights + self.layer_4x4.trainable_weights\n","        self.layer_4x4_vars = self.layer_4x4_vars_main + self.layer_input_4x4.trainable_weights\n","        \n","        self.layer_8x8_vars_main = self.layer_4x4_vars_main + self.layer_8x8.trainable_weights\n","        self.layer_8x8_vars = self.layer_8x8_vars_main + self.layer_input_8x8.trainable_weights + self.layer_input_4x4.trainable_weights\n","        \n","        self.layer_16x16_vars_main = self.layer_8x8_vars_main + self.layer_16x16.trainable_weights\n","        self.layer_16x16_vars = self.layer_16x16_vars_main + self.layer_input_16x16.trainable_weights + self.layer_input_8x8.trainable_weights\n","        \n","        self.layer_32x32_vars_main = self.layer_16x16_vars_main + self.layer_32x32.trainable_weights\n","        self.layer_32x32_vars = self.layer_32x32_vars_main + self.layer_input_32x32.trainable_weights + self.layer_input_16x16.trainable_weights\n","        \n","        self.layer_64x64_vars_main = self.layer_32x32_vars_main + self.layer_64x64.trainable_weights\n","        self.layer_64x64_vars = self.layer_64x64_vars_main + self.layer_input_64x64.trainable_weights + self.layer_input_32x32.trainable_weights\n","        \n","        self.layer_128x128_vars_main = self.layer_64x64_vars_main + self.layer_128x128.trainable_weights\n","        self.layer_128x128_vars = self.layer_128x128_vars_main + self.layer_input_128x128.trainable_weights + self.layer_input_64x64.trainable_weights\n","        \n","        self.layer_256x256_vars_main = self.layer_128x128_vars_main + self.layer_256x256.trainable_weights\n","        self.layer_256x256_vars = self.layer_256x256_vars_main + self.layer_input_256x256.trainable_weights + self.layer_input_128x128.trainable_weights\n","        \n","        self.layer_512x512_vars_main = self.layer_256x256_vars_main + self.layer_512x512.trainable_weights\n","        self.layer_512x512_vars = self.layer_512x512_vars_main + self.layer_input_512x512.trainable_weights + self.layer_input_256x256.trainable_weights\n","        \n","        \n","        \n","        \n","    @tf.function\n","    def model_4x4(self, inputs, training=False):\n","        x = self.layer_input_4x4(inputs)\n","        x = self.relu(x)\n","        x = self.layer_4x4(x)\n","        x = self.relu(x)\n","        \n","        x = self.flatten(x)\n","        x = self.layer_out(x)\n","        \n","        mean, logvar = tf.split(x, num_or_size_splits=2, axis=1)\n","        eps = tf.random.normal(shape=mean.shape)\n","        x = eps * tf.exp(logvar * .5) + mean\n","        \n","        return x, mean, logvar\n","     \n","    @tf.function   \n","    def model_8x8(self, inputs, training=False):\n","        old = self.pool(inputs)\n","        old = self.layer_input_4x4(old)\n","        old = self.relu(old)\n","        old = old * 1-(self.fader/self.fader_total)\n","        \n","        x = self.layer_input_8x8(inputs)\n","        x = self.relu(x)\n","        x = self.layer_8x8(x)\n","        x = self.pool(x)\n","        x = self.relu(x)\n","        x = x * (self.fader/self.fader_total)\n","        \n","        x = x + old\n","        \n","        x = self.layer_4x4(x)\n","        x = self.relu(x)\n","        \n","        x = self.flatten(x)\n","        x = self.layer_out(x)\n","        \n","        mean, logvar = tf.split(x, num_or_size_splits=2, axis=1)\n","        eps = tf.random.normal(shape=mean.shape)\n","        x = eps * tf.exp(logvar * .5) + mean\n","        \n","        return x, mean, logvar\n","       \n","    @tf.function \n","    def model_16x16(self, inputs, training=False):\n","        old = self.pool(inputs)\n","        old = self.layer_input_8x8(old)\n","        old = self.relu(old)\n","        old = old * 1-(self.fader/self.fader_total)\n","        \n","        x = self.layer_input_16x16(inputs)\n","        x = self.relu(x)\n","        x = self.layer_16x16(x)\n","        x = self.pool(x)\n","        x = self.relu(x)\n","        x = x * (self.fader/self.fader_total)\n","        \n","        x = x + old\n","        \n","        x = self.layer_8x8(x)\n","        x = self.pool(x)\n","        x = self.relu(x)\n","\n","        x = self.layer_4x4(x)\n","        x = self.relu(x)\n","\n","        x = self.flatten(x)\n","        x = self.layer_out(x)\n","        \n","        mean, logvar = tf.split(x, num_or_size_splits=2, axis=1)\n","        eps = tf.random.normal(shape=mean.shape)\n","        x = eps * tf.exp(logvar * .5) + mean\n","        \n","        return x, mean, logvar\n","     \n","    @tf.function   \n","    def model_32x32(self, inputs, training=False):\n","        old = self.pool(inputs)\n","        old = self.layer_input_16x16(old)\n","        old = self.relu(old)\n","        old = old * 1-(self.fader/self.fader_total)\n","        \n","        x = self.layer_input_32x32(inputs)\n","        x = self.relu(x)\n","        x = self.layer_32x32(x)\n","        x = self.pool(x)\n","        x = self.relu(x)\n","        x = x * (self.fader/self.fader_total)\n","        \n","        x = x + old\n","        \n","        x = self.layer_16x16(x)\n","        x = self.pool(x)\n","        x = self.relu(x)\n","\n","        x = self.layer_8x8(x)\n","        x = self.pool(x)\n","        x = self.relu(x)\n","\n","        x = self.layer_4x4(x)\n","        x = self.relu(x)\n","        \n","        x = self.flatten(x)\n","        x = self.layer_out(x)\n","        \n","        mean, logvar = tf.split(x, num_or_size_splits=2, axis=1)\n","        eps = tf.random.normal(shape=mean.shape)\n","        x = eps * tf.exp(logvar * .5) + mean\n","        \n","        return x, mean, logvar\n","        \n","    @tf.function\n","    def model_64x64(self, inputs, training=False):\n","        old = self.pool(inputs)\n","        old = self.layer_input_32x32(old)\n","        old = self.relu(old)\n","        old = old * 1-(self.fader/self.fader_total)\n","        \n","        x = self.layer_input_64x64(inputs)\n","        x = self.relu(x)\n","        x = self.layer_64x64(x)\n","        x = self.pool(x)\n","        x = self.relu(x)\n","        x = x * (self.fader/self.fader_total)\n","        \n","        x = x + old\n","        \n","        x = self.layer_32x32(x)\n","        x = self.pool(x)\n","        x = self.relu(x)\n","\n","        x = self.layer_16x16(x)\n","        x = self.pool(x)\n","        x = self.relu(x)\n","\n","        x = self.layer_8x8(x)\n","        x = self.pool(x)\n","        x = self.relu(x)\n","\n","        x = self.layer_4x4(x)\n","        x = self.relu(x)\n","        \n","        x = self.flatten(x)\n","        x = self.layer_out(x)\n","        \n","        mean, logvar = tf.split(x, num_or_size_splits=2, axis=1)\n","        eps = tf.random.normal(shape=mean.shape)\n","        x = eps * tf.exp(logvar * .5) + mean\n","        \n","        return x, mean, logvar\n","        \n","    @tf.function\n","    def model_128x128(self, inputs, training=False):\n","        old = self.pool(inputs)\n","        old = self.layer_input_64x64(old)\n","        old = self.relu(old)\n","        old = old * 1-(self.fader/self.fader_total)\n","        \n","        x = self.layer_input_128x128(inputs)        \n","        x = self.relu(x)\n","        x = self.layer_128x128(x)\n","        x = self.pool(x)\n","        x = self.relu(x)\n","        x = x * (self.fader/self.fader_total)\n","        \n","        x = x + old\n","        \n","        x = self.layer_64x64(x)\n","        x = self.pool(x)\n","        x = self.relu(x)\n","\n","        x = self.layer_32x32(x)\n","        x = self.pool(x)\n","        x = self.relu(x)\n","\n","        x = self.layer_16x16(x)\n","        x = self.pool(x)\n","        x = self.relu(x)\n","\n","        x = self.layer_8x8(x)\n","        x = self.pool(x)\n","        x = self.relu(x)\n","\n","        x = self.layer_4x4(x)\n","        x = self.relu(x)\n","        \n","        x = self.flatten(x)\n","        x = self.layer_out(x)\n","        \n","        mean, logvar = tf.split(x, num_or_size_splits=2, axis=1)\n","        eps = tf.random.normal(shape=mean.shape)\n","        x = eps * tf.exp(logvar * .5) + mean\n","        \n","        return x, mean, logvar\n","        \n","    @tf.function\n","    def model_256x256(self, inputs, training=False):\n","        old = self.pool(inputs)\n","        old = self.layer_input_128x128(old)\n","        old = self.relu(old)\n","        old = old * 1-(self.fader/self.fader_total)\n","        \n","        x = self.layer_input_256x256(inputs)        \n","        x = self.relu(x)\n","        x = self.layer_256x256(x)\n","        x = self.pool(x)\n","        x = self.relu(x)\n","        x = x * (self.fader/self.fader_total)\n","        \n","        x = x + old\n","        \n","        x = self.layer_128x128(x)\n","        x = self.pool(x)\n","        x = self.relu(x)\n","\n","        x = self.layer_64x64(x)\n","        x = self.pool(x)\n","        x = self.relu(x)\n","\n","        x = self.layer_32x32(x)\n","        x = self.pool(x)\n","        x = self.relu(x)\n","\n","        x = self.layer_16x16(x)\n","        x = self.pool(x)\n","        x = self.relu(x)\n","\n","        x = self.layer_8x8(x)\n","        x = self.pool(x)\n","        x = self.relu(x)\n","\n","        x = self.layer_4x4(x)\n","        x = self.relu(x)\n","        \n","        x = self.flatten(x)\n","        x = self.layer_out(x)\n","        \n","        mean, logvar = tf.split(x, num_or_size_splits=2, axis=1)\n","        eps = tf.random.normal(shape=mean.shape)\n","        x = eps * tf.exp(logvar * .5) + mean\n","        \n","        return x, mean, logvar\n","        \n","    @tf.function\n","    def model_512x512(self, inputs, training=False):\n","        old = self.pool(inputs)\n","        old = self.layer_input_256x256(old)\n","        old = self.relu(old)\n","        old = old * 1-(self.fader/self.fader_total)\n","        \n","        x = self.layer_input_512x512(inputs)\n","        x = self.relu(x)\n","        x = self.layer_512x512(x)\n","        x = self.pool(x)\n","        x = self.relu(x)\n","        x = x * (self.fader/self.fader_total)\n","        \n","        x = x + old\n","        \n","        x = self.layer_256x256(x)\n","        x = self.pool(x)\n","        x = self.relu(x)\n","        \n","        x = self.layer_128x128(x)\n","        x = self.pool(x)\n","        x = self.relu(x)\n","        \n","        x = self.layer_64x64(x)\n","        x = self.pool(x)\n","        x = self.relu(x)\n","\n","        x = self.layer_32x32(x)\n","        x = self.pool(x)\n","        x = self.relu(x)\n","\n","        x = self.layer_16x16(x)\n","        x = self.pool(x)\n","        x = self.relu(x)\n","\n","        x = self.layer_8x8(x)\n","        x = self.pool(x)\n","        x = self.relu(x)\n","\n","        x = self.layer_4x4(x)\n","        x = self.relu(x)\n","        \n","        x = self.flatten(x)\n","        x = self.layer_out(x)\n","        \n","        mean, logvar = tf.split(x, num_or_size_splits=2, axis=1)\n","        eps = tf.random.normal(shape=mean.shape)\n","        x = eps * tf.exp(logvar * .5) + mean\n","        \n","        return x, mean, logvar\n","        \n","    \n","    \n","    \n","\n","VAE = VAE_model()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["4 (1, 100)\n","8 (1, 100)\n","16 (1, 100)\n","32 (1, 100)\n","64 (1, 100)\n","128 (1, 100)\n","256 (1, 100)\n","512 (1, 100)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YiJor8cCgfF1","colab_type":"code","outputId":"fca04290-ebe9-4bf8-bcfb-61ff09ed6c96","executionInfo":{"status":"ok","timestamp":1562782335851,"user_tz":420,"elapsed":58043,"user":{"displayName":"Michael Jankowiak","photoUrl":"","userId":"13749907316228325380"}},"colab":{"base_uri":"https://localhost:8080/","height":153}},"source":["class generator_model(tf.keras.Model):\n","    @tf.function\n","    def __init__(self):\n","        super(generator_model, self).__init__()\n","        \n","        self.relu = layers.LeakyReLU()\n","        self.sigmoid = layers.Activation('sigmoid')\n","        self.layer_upsample = layers.UpSampling2D()\n","        \n","        self.layer_dense = layers.Dense(4*4*256, use_bias=False, input_shape=(100,))\n","        self.layer_dense_norm = layers.BatchNormalization()\n","        self.reshape_4x4 = layers.Reshape((4, 4, 256))\n","        self.layer_out_4x4 = layers.Conv2D(3, (1, 1), strides=1, padding='same', use_bias=False, kernel_initializer=initializers.he_normal())\n","        \n","        \n","        self.layer_8x8 = layers.Conv2D(128, (3, 3), strides=1, padding='same', use_bias=False, kernel_initializer=initializers.he_normal())\n","        self.layer_norm_8x8 = layers.BatchNormalization()\n","        self.layer_out_8x8 = layers.Conv2D(3, (1, 1), strides=1, padding='same', use_bias=False, kernel_initializer=initializers.he_normal())\n","        \n","\n","        self.layer_16x16 = layers.Conv2D(128, (3, 3), strides=1, padding='same', use_bias=False, kernel_initializer=initializers.he_normal())\n","        self.layer_norm_16x16 = layers.BatchNormalization()\n","        self.layer_out_16x16 = layers.Conv2D(3, (1, 1), strides=1, padding='same', use_bias=False, kernel_initializer=initializers.he_normal())\n","        \n","\n","        self.layer_32x32 = layers.Conv2D(64, (3, 3), strides=1, padding='same', use_bias=False, kernel_initializer=initializers.he_normal())\n","        self.layer_norm_32x32 = layers.BatchNormalization()\n","        self.layer_out_32x32 = layers.Conv2D(3, (1, 1), strides=1, padding='same', use_bias=False, kernel_initializer=initializers.he_normal())\n","\n","\n","        self.layer_64x64 = layers.Conv2D(64, (3, 3), strides=1, padding='same', use_bias=False, kernel_initializer=initializers.he_normal())\n","        self.layer_norm_64x64 = layers.BatchNormalization()\n","        self.layer_out_64x64 = layers.Conv2D(3, (1, 1), strides=1, padding='same', use_bias=False, kernel_initializer=initializers.he_normal())\n","\n","\n","        self.layer_128x128 = layers.Conv2D(32, (3, 3), strides=1, padding='same', use_bias=False, kernel_initializer=initializers.he_normal())\n","        self.layer_norm_128x128 = layers.BatchNormalization()\n","        self.layer_out_128x128 = layers.Conv2D(3, (1, 1), strides=1, padding='same', use_bias=False, kernel_initializer=initializers.he_normal())\n","        \n","\n","        self.layer_256x256 = layers.Conv2D(32, (3, 3), strides=1, padding='same', use_bias=False, kernel_initializer=initializers.he_normal())\n","        self.layer_norm_256x256 = layers.BatchNormalization()\n","        self.layer_out_256x256 = layers.Conv2D(3, (1, 1), strides=1, padding='same', use_bias=False, kernel_initializer=initializers.he_normal())\n","        \n","\n","        self.layer_512x512 = layers.Conv2D(16, (3, 3), strides=1, padding='same', use_bias=False, kernel_initializer=initializers.he_normal())\n","        self.layer_norm_512x512 = layers.BatchNormalization()\n","        self.layer_out_512x512 = layers.Conv2D(3, (1, 1), strides=1, padding='same', use_bias=False, kernel_initializer=initializers.he_normal())\n","        \n","        \n","        self.op = tf.keras.optimizers.Adam(1e-4)\n","        self.fader_total = 500\n","        self.fader = self.fader_total - 1\n","        \n","        \n","        noise = tf.random.normal([1, 100])\n","\n","        output = self.model_4x4(noise)\n","        print(output[1].shape)\n","\n","        output = self.model_8x8(noise)\n","        print(output[1].shape)\n","\n","        output = self.model_16x16(noise)\n","        print(output[1].shape)\n","\n","        output = self.model_32x32(noise)\n","        print(output[1].shape)\n","\n","        output = self.model_64x64(noise)\n","        print(output[1].shape)\n","\n","        output = self.model_128x128(noise)\n","        print(output[1].shape)\n","\n","        output = self.model_256x256(noise)\n","        print(output[1].shape)\n","\n","        output = self.model_512x512(noise)\n","        print(output[1].shape)\n","        \n","        \n","        self.layer_4x4_vars_main = self.layer_dense.trainable_weights + self.layer_dense_norm.trainable_weights\n","        self.layer_4x4_vars = self.layer_4x4_vars_main + self.layer_out_4x4.trainable_weights\n","        \n","        self.layer_8x8_vars_main = self.layer_4x4_vars_main + self.layer_8x8.trainable_weights + self.layer_norm_8x8.trainable_weights\n","        self.layer_8x8_vars = self.layer_8x8_vars_main + self.layer_out_8x8.trainable_weights + self.layer_out_4x4.trainable_weights\n","        \n","        self.layer_16x16_vars_main = self.layer_8x8_vars_main + self.layer_16x16.trainable_weights + self.layer_norm_16x16.trainable_weights\n","        self.layer_16x16_vars = self.layer_16x16_vars_main + self.layer_out_16x16.trainable_weights + self.layer_out_8x8.trainable_weights\n","        \n","        self.layer_32x32_vars_main = self.layer_16x16_vars_main + self.layer_32x32.trainable_weights + self.layer_norm_32x32.trainable_weights\n","        self.layer_32x32_vars = self.layer_32x32_vars_main + self.layer_out_32x32.trainable_weights + self.layer_out_16x16.trainable_weights\n","        \n","        self.layer_64x64_vars_main = self.layer_32x32_vars_main + self.layer_64x64.trainable_weights + self.layer_norm_64x64.trainable_weights\n","        self.layer_64x64_vars = self.layer_64x64_vars_main + self.layer_out_64x64.trainable_weights + self.layer_out_32x32.trainable_weights\n","        \n","        self.layer_128x128_vars_main = self.layer_64x64_vars_main + self.layer_128x128.trainable_weights + self.layer_norm_128x128.trainable_weights\n","        self.layer_128x128_vars = self.layer_128x128_vars_main + self.layer_out_128x128.trainable_weights + self.layer_out_64x64.trainable_weights\n","        \n","        self.layer_256x256_vars_main = self.layer_128x128_vars_main + self.layer_256x256.trainable_weights + self.layer_norm_256x256.trainable_weights\n","        self.layer_256x256_vars = self.layer_256x256_vars_main + self.layer_out_256x256.trainable_weights + self.layer_out_128x128.trainable_weights\n","        \n","        self.layer_512x512_vars_main = self.layer_256x256_vars_main + self.layer_512x512.trainable_weights + self.layer_norm_512x512.trainable_weights\n","        self.layer_512x512_vars = self.layer_512x512_vars_main + self.layer_out_512x512.trainable_weights + self.layer_out_256x256.trainable_weights\n","        \n","        \n","    @tf.function\n","    def model_4x4(self, inputs, fader=500, training=False):\n","        main = self.layer_dense(inputs)\n","        main = self.layer_dense_norm(main, training=training)\n","        main = self.relu(main)\n","        main = self.reshape_4x4(main)\n","        to_rgb = self.layer_out_4x4(main)\n","        \n","        return main, to_rgb\n","\n","    @tf.function\n","    def model_8x8(self, inputs, fader=500, training=False):\n","        main, old_rgb = self.model_4x4(inputs, training=training)\n","        \n","        old_rgb = self.layer_upsample(old_rgb)\n","        old_rgb = old_rgb * 1-(fader/self.fader_total)\n","        \n","        main = self.layer_upsample(main)\n","        main = self.layer_8x8(main)\n","        main = self.layer_norm_8x8(main, training=training)\n","        main = self.relu(main)\n","        \n","        to_rbg = self.layer_out_8x8(main)\n","        to_rbg = to_rbg * (fader/self.fader_total)\n","        \n","        to_rbg = to_rbg + old_rgb\n","        \n","        return main, to_rbg\n","        \n","    @tf.function\n","    def model_16x16(self, inputs, fader=500, training=False):\n","        main, old_rgb = self.model_8x8(inputs, training=training)\n","        \n","        old_rgb = self.layer_upsample(old_rgb)\n","        old_rgb = old_rgb * 1-(self.fader/self.fader_total)\n","        \n","        main = self.layer_upsample(main)\n","        main = self.layer_16x16(main)\n","        main = self.layer_norm_16x16(main, training=training)\n","        main = self.relu(main)\n","        \n","        to_rbg = self.layer_out_16x16(main)\n","        to_rbg = to_rbg * (self.fader/self.fader_total)\n","        \n","        to_rbg = to_rbg + old_rgb\n","        \n","        return main, to_rbg\n","        \n","    @tf.function\n","    def model_32x32(self, inputs, fader=500, training=False):\n","        main, old_rgb = self.model_16x16(inputs, training=training)\n","        \n","        old_rgb = self.layer_upsample(old_rgb)\n","        old_rgb = old_rgb * 1-(self.fader/self.fader_total)\n","        \n","        main = self.layer_upsample(main)\n","        main = self.layer_32x32(main)\n","        main = self.layer_norm_32x32(main, training=training)\n","        main = self.relu(main)\n","        \n","        to_rbg = self.layer_out_32x32(main)\n","        to_rbg = to_rbg * (self.fader/self.fader_total)\n","        \n","        to_rbg = to_rbg + old_rgb\n","        \n","        return main, to_rbg\n","        \n","    @tf.function\n","    def model_64x64(self, inputs, fader=500, training=False):\n","        main, old_rgb = self.model_32x32(inputs, training=training)\n","        \n","        old_rgb = self.layer_upsample(old_rgb)\n","        old_rgb = old_rgb * 1-(self.fader/self.fader_total)\n","        \n","        main = self.layer_upsample(main)\n","        main = self.layer_64x64(main)\n","        main = self.layer_norm_64x64(main, training=training)\n","        main = self.relu(main)\n","        \n","        to_rbg = self.layer_out_64x64(main)\n","        to_rbg = to_rbg * (self.fader/self.fader_total)\n","        \n","        to_rbg = to_rbg + old_rgb\n","        \n","        return main, to_rbg\n","        \n","    @tf.function\n","    def model_128x128(self, inputs, fader=500, training=False):\n","        main, old_rgb = self.model_64x64(inputs, training=training)\n","        \n","        old_rgb = self.layer_upsample(old_rgb)\n","        old_rgb = old_rgb * 1-(self.fader/self.fader_total)\n","        \n","        main = self.layer_upsample(main)\n","        main = self.layer_128x128(main)\n","        main = self.layer_norm_128x128(main, training=training)\n","        main = self.relu(main)\n","        \n","        to_rbg = self.layer_out_128x128(main)\n","        to_rbg = to_rbg * (self.fader/self.fader_total)\n","        \n","        to_rbg = to_rbg + old_rgb\n","        \n","        return main, to_rbg\n","       \n","    @tf.function \n","    def model_256x256(self, inputs, fader=500, training=False):\n","        main, old_rgb = self.model_128x128(inputs, training=training)\n","        \n","        old_rgb = self.layer_upsample(old_rgb)\n","        old_rgb = old_rgb * 1-(self.fader/self.fader_total)\n","        \n","        main = self.layer_upsample(main)\n","        main = self.layer_256x256(main)\n","        main = self.layer_norm_256x256(main, training=training)\n","        main = self.relu(main)\n","        \n","        to_rbg = self.layer_out_256x256(main)\n","        to_rbg = to_rbg * (self.fader/self.fader_total)\n","        \n","        to_rbg = to_rbg + old_rgb\n","        \n","        return main, to_rbg\n","       \n","    @tf.function \n","    def model_512x512(self, inputs, fader=500, training=False):\n","        main, old_rgb = self.model_256x256(inputs, training=training)\n","        \n","        old_rgb = self.layer_upsample(old_rgb)\n","        old_rgb = old_rgb * 1-(self.fader/self.fader_total)\n","        \n","        main = self.layer_upsample(main)\n","        main = self.layer_512x512(main)\n","        main = self.layer_norm_512x512(main, training=training)\n","        main = self.relu(main)\n","        \n","        to_rbg = self.layer_out_512x512(main)\n","        to_rbg = to_rbg * (self.fader/self.fader_total)\n","        \n","        to_rbg = to_rbg + old_rgb\n","        \n","        return main, to_rbg\n","    \n","    \n","\n","generator = generator_model()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(1, 4, 4, 3)\n","(1, 8, 8, 3)\n","(1, 16, 16, 3)\n","(1, 32, 32, 3)\n","(1, 64, 64, 3)\n","(1, 128, 128, 3)\n","(1, 256, 256, 3)\n","(1, 512, 512, 3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"28XJwHopnU33","outputId":"3ac7455a-ebb5-44af-9585-562c017dc84e","executionInfo":{"status":"ok","timestamp":1562782342668,"user_tz":420,"elapsed":64850,"user":{"displayName":"Michael Jankowiak","photoUrl":"","userId":"13749907316228325380"}},"colab":{"base_uri":"https://localhost:8080/","height":153}},"source":["class discriminator_model(tf.keras.Model):\n","    @tf.function\n","    def __init__(self):\n","        super(discriminator_model, self).__init__()\n","        \n","        self.relu = layers.LeakyReLU()\n","        self.dropout = layers.Dropout(0.3)\n","        self.pool = layers.AveragePooling2D(strides=2, padding='same')\n","        self.gaus_noise = layers.GaussianNoise(0.3)\n","        \n","        \n","        self.layer_input_512x512 = layers.Conv2D(16, (1, 1), strides=1, padding='same', kernel_initializer=initializers.he_normal())\n","        self.layer_512x512 = layers.Conv2D(16, (3, 3), strides=1, padding='same', kernel_initializer=initializers.he_normal())\n","        \n","        \n","        self.layer_input_256x256 = layers.Conv2D(16, (1, 1), strides=1, padding='same', kernel_initializer=initializers.he_normal())\n","        self.layer_256x256 = layers.Conv2D(32, (3, 3), strides=1, padding='same', kernel_initializer=initializers.he_normal())\n","        \n","        \n","        self.layer_input_128x128 = layers.Conv2D(32, (1, 1), strides=1, padding='same', kernel_initializer=initializers.he_normal())\n","        self.layer_128x128 = layers.Conv2D(32, (3, 3), strides=1, padding='same', kernel_initializer=initializers.he_normal())\n","        \n","        \n","        self.layer_input_64x64 = layers.Conv2D(32, (1, 1), strides=1, padding='same', kernel_initializer=initializers.he_normal())\n","        self.layer_64x64 = layers.Conv2D(64, (3, 3), strides=1, padding='same', kernel_initializer=initializers.he_normal())\n","        \n","        \n","        self.layer_input_32x32 = layers.Conv2D(64, (1, 1), strides=1, padding='same', kernel_initializer=initializers.he_normal())\n","        self.layer_32x32 = layers.Conv2D(64, (3, 3), strides=1, padding='same', kernel_initializer=initializers.he_normal())\n","        \n","        \n","        self.layer_input_16x16 = layers.Conv2D(64, (1, 1), strides=1, padding='same', kernel_initializer=initializers.he_normal())\n","        self.layer_16x16 = layers.Conv2D(128, (3, 3), strides=1, padding='same', kernel_initializer=initializers.he_normal())\n","        \n","        \n","        self.layer_input_8x8 = layers.Conv2D(128, (1, 1), strides=1, padding='same', kernel_initializer=initializers.he_normal())\n","        self.layer_8x8 = layers.Conv2D(128, (3, 3), strides=1, padding='same', kernel_initializer=initializers.he_normal())\n","        \n","        \n","        self.layer_input_4x4 = layers.Conv2D(128, (1, 1), strides=1, padding='same', name='layer_input_4x4')\n","        self.layer_4x4 = layers.Conv2D(256, 4, strides=1, padding='same', name='layer_4x4')\n","        \n","        \n","        self.flatten = layers.Flatten()\n","        self.layer_out = layers.Dense(1, name='layer_out')\n","        \n","        \n","        self.op = tf.keras.optimizers.Adam(1e-4)\n","        self.fader_total = 500\n","        self.fader = self.fader_total - 1\n","        \n","\n","        noise = self.gaus_noise(tf.random.normal([1, 4, 4, 3]))\n","        output = self.model_4x4(noise)\n","        print(4, output.shape)\n","\n","        noise = self.gaus_noise(tf.random.normal([1, 8, 8, 3]))\n","        output = self.model_8x8(noise)\n","        print(8, output.shape)\n","\n","        noise = self.gaus_noise(tf.random.normal([1, 16, 16, 3]))\n","        output = self.model_16x16(noise)\n","        print(16, output.shape)\n","\n","        noise = self.gaus_noise(tf.random.normal([1, 32, 32, 3]))\n","        output = self.model_32x32(noise)\n","        print(32, output.shape)\n","\n","        noise = self.gaus_noise(tf.random.normal([1, 64, 64, 3]))\n","        output = self.model_64x64(noise)\n","        print(64, output.shape)\n","\n","        noise = self.gaus_noise(tf.random.normal([1, 128, 128, 3]))\n","        output = self.model_128x128(noise)\n","        print(128, output.shape)\n","\n","        noise = self.gaus_noise(tf.random.normal([1, 256, 256, 3]))\n","        output = self.model_256x256(noise)\n","        print(256, output.shape)\n","\n","        noise = self.gaus_noise(tf.random.normal([1, 512, 512, 3]))\n","        output = self.model_512x512(noise)\n","        print(512, output.shape)\n","        \n","        \n","        self.layer_4x4_vars_main = self.layer_out.trainable_weights + self.layer_4x4.trainable_weights\n","        self.layer_4x4_vars = self.layer_4x4_vars_main + self.layer_input_4x4.trainable_weights\n","        \n","        self.layer_8x8_vars_main = self.layer_4x4_vars_main + self.layer_8x8.trainable_weights\n","        self.layer_8x8_vars = self.layer_8x8_vars_main + self.layer_input_8x8.trainable_weights + self.layer_input_4x4.trainable_weights\n","        \n","        self.layer_16x16_vars_main = self.layer_8x8_vars_main + self.layer_16x16.trainable_weights\n","        self.layer_16x16_vars = self.layer_16x16_vars_main + self.layer_input_16x16.trainable_weights + self.layer_input_8x8.trainable_weights\n","        \n","        self.layer_32x32_vars_main = self.layer_16x16_vars_main + self.layer_32x32.trainable_weights\n","        self.layer_32x32_vars = self.layer_32x32_vars_main + self.layer_input_32x32.trainable_weights + self.layer_input_16x16.trainable_weights\n","        \n","        self.layer_64x64_vars_main = self.layer_32x32_vars_main + self.layer_64x64.trainable_weights\n","        self.layer_64x64_vars = self.layer_64x64_vars_main + self.layer_input_64x64.trainable_weights + self.layer_input_32x32.trainable_weights\n","        \n","        self.layer_128x128_vars_main = self.layer_64x64_vars_main + self.layer_128x128.trainable_weights\n","        self.layer_128x128_vars = self.layer_128x128_vars_main + self.layer_input_128x128.trainable_weights + self.layer_input_64x64.trainable_weights\n","        \n","        self.layer_256x256_vars_main = self.layer_128x128_vars_main + self.layer_256x256.trainable_weights\n","        self.layer_256x256_vars = self.layer_256x256_vars_main + self.layer_input_256x256.trainable_weights + self.layer_input_128x128.trainable_weights\n","        \n","        self.layer_512x512_vars_main = self.layer_256x256_vars_main + self.layer_512x512.trainable_weights\n","        self.layer_512x512_vars = self.layer_512x512_vars_main + self.layer_input_512x512.trainable_weights + self.layer_input_256x256.trainable_weights\n","        \n","        \n","    @tf.function\n","    def model_4x4(self, main, merging_input, fader=500, training=False):\n","        old = merging_input * (self.fader/self.fader_total)\n","        \n","        main = self.layer_input_4x4(main)\n","        main = self.relu(main)\n","        main = main * 1-(fader/self.fader_total)\n","        \n","        x = main + old\n","        \n","        x = self.layer_4x4(x)\n","        x = self.relu(x)\n","        \n","        x = self.flatten(x)\n","        x = self.layer_out(x)\n","        \n","        return x\n","     \n","    @tf.function   \n","    def model_8x8(self, inputs, training=False):\n","        x = self.layer_input_8x8(inputs)\n","        x = self.relu(x)\n","        x = self.layer_8x8(x)\n","        x = self.pool(x)\n","        x = self.relu(x)\n","        \n","\n","        old = self.pool(inputs)\n","        \n","        return x\n","       \n","    @tf.function \n","    def model_16x16(self, inputs, training=False):\n","        old = self.pool(inputs)\n","        old = self.layer_input_8x8(old)\n","        old = self.relu(old)\n","        old = old * 1-(self.fader/self.fader_total)\n","        \n","        x = self.layer_input_16x16(inputs)\n","        x = self.relu(x)\n","        x = self.layer_16x16(x)\n","        x = self.pool(x)\n","        x = self.relu(x)\n","        x = x * (self.fader/self.fader_total)\n","        \n","        x = x + old\n","        \n","        x = self.layer_8x8(x)\n","        x = self.pool(x)\n","        x = self.relu(x)\n","\n","        x = self.layer_4x4(x)\n","        x = self.relu(x)\n","\n","        \n","        x = self.flatten(x)\n","        x = self.layer_out(x)\n","        \n","        return x\n","     \n","    @tf.function   \n","    def model_32x32(self, inputs, training=False):\n","        old = self.pool(inputs)\n","        old = self.layer_input_16x16(old)\n","        old = self.relu(old)\n","        old = old * 1-(self.fader/self.fader_total)\n","        \n","        x = self.layer_input_32x32(inputs)\n","        x = self.relu(x)\n","        x = self.layer_32x32(x)\n","        x = self.pool(x)\n","        x = self.relu(x)\n","        x = x * (self.fader/self.fader_total)\n","        \n","        x = x + old\n","        \n","        x = self.layer_16x16(x)\n","        x = self.pool(x)\n","        x = self.relu(x)\n","\n","        x = self.layer_8x8(x)\n","        x = self.pool(x)\n","        x = self.relu(x)\n","\n","        x = self.layer_4x4(x)\n","        x = self.relu(x)\n","\n","        \n","        x = self.flatten(x)\n","        x = self.layer_out(x)\n","        \n","        return x\n","        \n","    @tf.function\n","    def model_64x64(self, inputs, training=False):\n","        old = self.pool(inputs)\n","        old = self.layer_input_32x32(old)\n","        old = self.relu(old)\n","        old = old * 1-(self.fader/self.fader_total)\n","        \n","        x = self.layer_input_64x64(inputs)\n","        x = self.relu(x)\n","        x = self.layer_64x64(x)\n","        x = self.pool(x)\n","        x = self.relu(x)\n","        x = x * (self.fader/self.fader_total)\n","        \n","        x = x + old\n","        \n","        x = self.layer_32x32(x)\n","        x = self.pool(x)\n","        x = self.relu(x)\n","\n","        x = self.layer_16x16(x)\n","        x = self.pool(x)\n","        x = self.relu(x)\n","\n","        x = self.layer_8x8(x)\n","        x = self.pool(x)\n","        x = self.relu(x)\n","\n","        x = self.layer_4x4(x)\n","        x = self.relu(x)\n","\n","        \n","        x = self.flatten(x)\n","        x = self.layer_out(x)\n","        \n","        return x\n","        \n","    @tf.function\n","    def model_128x128(self, inputs, training=False):\n","        old = self.pool(inputs)\n","        old = self.layer_input_64x64(old)\n","        old = self.relu(old)\n","        old = old * 1-(self.fader/self.fader_total)\n","        \n","        x = self.layer_input_128x128(inputs)        \n","        x = self.relu(x)\n","        x = self.layer_128x128(x)\n","        x = self.pool(x)\n","        x = self.relu(x)\n","        x = x * (self.fader/self.fader_total)\n","        \n","        x = x + old\n","        \n","        x = self.layer_64x64(x)\n","        x = self.pool(x)\n","        x = self.relu(x)\n","\n","        x = self.layer_32x32(x)\n","        x = self.pool(x)\n","        x = self.relu(x)\n","\n","        x = self.layer_16x16(x)\n","        x = self.pool(x)\n","        x = self.relu(x)\n","\n","        x = self.layer_8x8(x)\n","        x = self.pool(x)\n","        x = self.relu(x)\n","\n","        x = self.layer_4x4(x)\n","        x = self.relu(x)\n","\n","        \n","        x = self.flatten(x)\n","        x = self.layer_out(x)\n","        \n","        return x\n","        \n","    @tf.function\n","    def model_256x256(self, inputs, training=False):\n","        old = self.pool(inputs)\n","        old = self.layer_input_128x128(old)\n","        old = self.relu(old)\n","        old = old * 1-(self.fader/self.fader_total)\n","        \n","        x = self.layer_input_256x256(inputs)        \n","        x = self.relu(x)\n","        x = self.layer_256x256(x)\n","        x = self.pool(x)\n","        x = self.relu(x)\n","        x = x * (self.fader/self.fader_total)\n","        \n","        x = x + old\n","        \n","        x = self.layer_128x128(x)\n","        x = self.pool(x)\n","        x = self.relu(x)\n","\n","        x = self.layer_64x64(x)\n","        x = self.pool(x)\n","        x = self.relu(x)\n","\n","        x = self.layer_32x32(x)\n","        x = self.pool(x)\n","        x = self.relu(x)\n","\n","        x = self.layer_16x16(x)\n","        x = self.pool(x)\n","        x = self.relu(x)\n","\n","        x = self.layer_8x8(x)\n","        x = self.pool(x)\n","        x = self.relu(x)\n","\n","        x = self.layer_4x4(x)\n","        x = self.relu(x)\n","\n","        \n","        x = self.flatten(x)\n","        x = self.layer_out(x)\n","        \n","        return x\n","        \n","    @tf.function\n","    def model_512x512(self, inputs, training=False):\n","        old = self.pool(inputs)\n","        old = self.layer_input_256x256(old)\n","        old = self.relu(old)\n","        old = old * 1-(self.fader/self.fader_total)\n","        \n","        x = self.layer_input_512x512(inputs)\n","        x = self.relu(x)\n","        x = self.layer_512x512(x)\n","        x = self.pool(x)\n","        x = self.relu(x)\n","        x = x * (self.fader/self.fader_total)\n","        \n","        x = x + old\n","        \n","        x = self.layer_256x256(x)\n","        x = self.pool(x)\n","        x = self.relu(x)\n","        \n","        x = self.layer_128x128(x)\n","        x = self.pool(x)\n","        x = self.relu(x)\n","        \n","        x = self.layer_64x64(x)\n","        x = self.pool(x)\n","        x = self.relu(x)\n","\n","        x = self.layer_32x32(x)\n","        x = self.pool(x)\n","        x = self.relu(x)\n","\n","        x = self.layer_16x16(x)\n","        x = self.pool(x)\n","        x = self.relu(x)\n","\n","        x = self.layer_8x8(x)\n","        x = self.pool(x)\n","        x = self.relu(x)\n","\n","        x = self.layer_4x4(x)\n","        x = self.relu(x)\n","\n","        \n","        x = self.flatten(x)\n","        x = self.layer_out(x)\n","        \n","        return x\n","        \n","    \n","    \n","    \n","\n","discriminator = discriminator_model()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["4 (1, 1)\n","8 (1, 4, 4, 128)\n","16 (1, 1)\n","32 (1, 1)\n","64 (1, 1)\n","128 (1, 1)\n","256 (1, 1)\n","512 (1, 1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"eKRGA8CphHkm","colab_type":"code","colab":{}},"source":["cross_entropy_logits = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n","\n","\n","@tf.function\n","def log_normal_pdf(sample, mean, logvar, raxis=1):\n","    log2pi = tf.math.log(2. * np.pi)\n","    return tf.reduce_sum(\n","        -.5 * ((sample - mean) ** 2. * tf.exp(-logvar) + logvar + log2pi),\n","        axis=raxis)\n","\n","@tf.function\n","def regulerizer_loss(z, mean, logvar, generated_images, images):\n","    logpx_z = cross_entropy_logits(generated_images, images)\n","    logpz = tf.math.reduce_mean(log_normal_pdf(z, 0., 0.))\n","    logqz_x = tf.math.reduce_mean(log_normal_pdf(z, mean, logvar))\n","    return -(logpx_z + logpz - logqz_x)\n","\n","@tf.function\n","def discriminator_loss(real_output, fake_output):\n","    real_loss = cross_entropy_logits(tf.ones_like(real_output), real_output)\n","    fake_loss = cross_entropy_logits(tf.zeros_like(fake_output), fake_output)\n","    total_loss = real_loss + fake_loss\n","    return total_loss\n","\n","@tf.function\n","def generator_loss(fake_output):\n","    total_loss = cross_entropy_logits(tf.ones_like(fake_output), fake_output)\n","    return total_loss\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2yvi-hvahmA5","colab_type":"code","outputId":"35e0f43c-ef64-4261-c3f3-c3d686f2ffd1","executionInfo":{"status":"ok","timestamp":1562782342673,"user_tz":420,"elapsed":64842,"user":{"displayName":"Michael Jankowiak","photoUrl":"","userId":"13749907316228325380"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["EPOCHS = 100\n","noise_dim = 100\n","num_examples_to_generate = 49\n","\n","\n","    \n","seed = tf.Variable(tf.random.normal([num_examples_to_generate, noise_dim]))\n","\n","checkpoint_dir = path + folder +'_checkpoints'\n","checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n","checkpoint = tf.train.Checkpoint(seed=seed,\n","                                 step=tf.Variable(0),\n","                                 level=tf.Variable(0),\n","                                 fader=tf.Variable(0, dtype=tf.float32),\n","                                 VAE=VAE,\n","                                 generator=generator,\n","                                 discriminator=discriminator)\n","\n","\n","\n","if continue_training:\n","    checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n","    print(checkpoint.step)\n","    print('Loaded!')\n","else:\n","    try:\n","        shutil.rmtree(path+folder+'_imgs/')\n","    except: pass\n","    os.mkdir(path+folder+'_imgs')\n","    try:\n","        os.mkdir(path+folder+'_checkpoints')\n","    except: pass\n","    try:\n","        os.mkdir(path+folder+'_graphs')\n","    except: pass\n","    print(checkpoint.step)\n","    print('New!')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["<tf.Variable 'Variable:0' shape=() dtype=int32, numpy=0>\n","New!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_YVGtS8RaMKJ","colab_type":"code","colab":{}},"source":["@tf.function\n","def train_step_4x4(images):\n","\n","    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n","        \n","        images_with_gaus = images\n","        images_with_gaus = discriminator.gaus_noise(images)\n","        \n","        z, mean, logvar = VAE.model_4x4(images, training=True)\n","        \n","        generated_images = generator.sigmoid(generator.model_4x4(z, fader=checkpoint.fader, training=True)[1])\n","        generated_images_with_gaus = generated_images\n","        generated_images_with_gaus = discriminator.gaus_noise(generated_images)\n","\n","        \n","        real_output = discriminator.model_4x4(images_with_gaus, training=True)\n","        fake_output = discriminator.model_4x4(generated_images_with_gaus, training=True)\n","        \n","        \n","        reg_loss = regulerizer_loss(z, mean, logvar, generated_images_with_gaus, images)\n","        gen_loss = generator_loss(fake_output)\n","        total_gen_loss = gen_loss + (0.1*reg_loss)\n","        disc_loss = discriminator_loss(real_output, fake_output)\n","\n","    gradients_of_generator = gen_tape.gradient(total_gen_loss, generator.layer_4x4_vars+VAE.layer_4x4_vars)\n","    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.layer_4x4_vars)\n","\n","    generator.op.apply_gradients(zip(gradients_of_generator, generator.layer_4x4_vars+VAE.layer_4x4_vars))\n","    discriminator.op.apply_gradients(zip(gradients_of_discriminator, discriminator.layer_4x4_vars))\n","    \n","    return gen_loss, disc_loss\n","    \n","    \n","@tf.function\n","def train_step_8x8(images):\n","\n","    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n","        \n","        images_with_gaus = images\n","        images_with_gaus = discriminator.gaus_noise(images)\n","        \n","        z, mean, logvar = VAE.model_8x8(images, training=True)\n","        \n","        generated_images = generator.sigmoid(generator.model_8x8(z, fader=checkpoint.fader, training=True)[1])\n","        generated_images_with_gaus = generated_images\n","        generated_images_with_gaus = discriminator.gaus_noise(generated_images)\n","\n","        \n","        real_output = discriminator.model_8x8(images_with_gaus, training=True)\n","        fake_output = discriminator.model_8x8(generated_images_with_gaus, training=True)\n","        \n","        \n","        reg_loss = regulerizer_loss(z, mean, logvar, generated_images_with_gaus, images)\n","        gen_loss = generator_loss(fake_output)\n","        total_gen_loss = gen_loss + (0.1*reg_loss)\n","        disc_loss = discriminator_loss(real_output, fake_output)\n","\n","    gradients_of_generator = gen_tape.gradient(total_gen_loss, generator.layer_8x8_vars+VAE.layer_8x8_vars)\n","    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.layer_8x8_vars)\n","\n","    generator.op.apply_gradients(zip(gradients_of_generator, generator.layer_8x8_vars+VAE.layer_8x8_vars))\n","    discriminator.op.apply_gradients(zip(gradients_of_discriminator, discriminator.layer_8x8_vars))\n","    \n","    return gen_loss, disc_loss\n","    \n","    \n","@tf.function\n","def train_step_16x16(images):\n","\n","    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n","        \n","        images_with_gaus = images\n","        images_with_gaus = discriminator.gaus_noise(images)\n","        \n","        z, mean, logvar = VAE.model_16x16(images, training=True)\n","        \n","        generated_images = generator.sigmoid(generator.model_16x16(z, fader=checkpoint.fader, training=True)[1])\n","        generated_images_with_gaus = generated_images\n","        generated_images_with_gaus = discriminator.gaus_noise(generated_images)\n","\n","        \n","        real_output = discriminator.model_16x16(images_with_gaus, training=True)\n","        fake_output = discriminator.model_16x16(generated_images_with_gaus, training=True)\n","        \n","        \n","        reg_loss = regulerizer_loss(z, mean, logvar, generated_images_with_gaus, images)\n","        gen_loss = generator_loss(fake_output)\n","        total_gen_loss = gen_loss + (0.1*reg_loss)\n","        disc_loss = discriminator_loss(real_output, fake_output)\n","\n","    gradients_of_generator = gen_tape.gradient(total_gen_loss, generator.layer_16x16_vars+VAE.layer_16x16_vars)\n","    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.layer_16x16_vars)\n","\n","    generator.op.apply_gradients(zip(gradients_of_generator, generator.layer_16x16_vars+VAE.layer_16x16_vars))\n","    discriminator.op.apply_gradients(zip(gradients_of_discriminator, discriminator.layer_16x16_vars))\n","    \n","    return gen_loss, disc_loss\n","    \n","    \n","@tf.function\n","def train_step_32x32(images):\n","    noise = tf.random.normal([images.shape[0], noise_dim])\n","\n","    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n","        \n","        images_with_gaus = images\n","        images_with_gaus = discriminator.gaus_noise(images)\n","        \n","        z, mean, logvar = VAE.model_32x32(images, training=True)\n","        \n","        generated_images = generator.sigmoid(generator.model_32x32(z, fader=checkpoint.fader, training=True)[1])\n","        generated_images_with_gaus = generated_images\n","        generated_images_with_gaus = discriminator.gaus_noise(generated_images)\n","\n","        \n","        real_output = discriminator.model_32x32(images_with_gaus, training=True)\n","        fake_output = discriminator.model_32x32(generated_images_with_gaus, training=True)\n","        \n","        \n","        reg_loss = regulerizer_loss(z, mean, logvar, generated_images_with_gaus, images)\n","        gen_loss = generator_loss(fake_output)\n","        total_gen_loss = gen_loss + (0.1*reg_loss)\n","        disc_loss = discriminator_loss(real_output, fake_output)\n","\n","    gradients_of_generator = gen_tape.gradient(total_gen_loss, generator.layer_32x32_vars+VAE.layer_32x32_vars)\n","    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.layer_32x32_vars)\n","\n","    generator.op.apply_gradients(zip(gradients_of_generator, generator.layer_32x32_vars+VAE.layer_32x32_vars))\n","    discriminator.op.apply_gradients(zip(gradients_of_discriminator, discriminator.layer_32x32_vars))\n","    \n","    return gen_loss, disc_loss\n","    \n","    \n","@tf.function\n","def train_step_64x64(images):\n","\n","    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n","        \n","        images_with_gaus = discriminator.gaus_noise(images)\n","        \n","        z, mean, logvar = VAE.model_64x64(images, training=True)\n","        \n","        generated_images = generator.sigmoid(generator.model_64x64(z, fader=checkpoint.fader, training=True)[1])\n","        generated_images_with_gaus = discriminator.gaus_noise(generated_images)\n","\n","        \n","        real_output = discriminator.model_64x64(images_with_gaus, training=True)\n","        fake_output = discriminator.model_64x64(generated_images_with_gaus, training=True)\n","        \n","        \n","        reg_loss = regulerizer_loss(z, mean, logvar, generated_images_with_gaus, images)\n","        gen_loss = generator_loss(fake_output)\n","        total_gen_loss = gen_loss + (0.1*reg_loss)\n","        disc_loss = discriminator_loss(real_output, fake_output)\n","\n","    gradients_of_generator = gen_tape.gradient(total_gen_loss, generator.layer_64x64_vars+VAE.layer_64x64_vars)\n","    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.layer_64x64_vars)\n","\n","    generator.op.apply_gradients(zip(gradients_of_generator, generator.layer_64x64_vars+VAE.layer_64x64_vars))\n","    discriminator.op.apply_gradients(zip(gradients_of_discriminator, discriminator.layer_64x64_vars))\n","    \n","    return gen_loss, disc_loss\n","    \n","    \n","@tf.function\n","def train_step_128x128(images):\n","\n","    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n","        \n","        images_with_gaus = discriminator.gaus_noise(images)\n","        \n","        z, mean, logvar = VAE.model_128x128(images, training=True)\n","        \n","        generated_images = generator.sigmoid(generator.model_128x128(z, fader=checkpoint.fader, training=True)[1])\n","        generated_images_with_gaus = discriminator.gaus_noise(generated_images)\n","\n","        \n","        real_output = discriminator.model_128x128(images_with_gaus, training=True)\n","        fake_output = discriminator.model_128x128(generated_images_with_gaus, training=True)\n","        \n","        \n","        reg_loss = regulerizer_loss(z, mean, logvar, generated_images_with_gaus, images)\n","        gen_loss = generator_loss(fake_output)\n","        total_gen_loss = gen_loss + (0.1*reg_loss)\n","        disc_loss = discriminator_loss(real_output, fake_output)\n","\n","    gradients_of_generator = gen_tape.gradient(total_gen_loss, generator.layer_128x128_vars+VAE.layer_128x128_vars)\n","    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.layer_128x128_vars)\n","\n","    generator.op.apply_gradients(zip(gradients_of_generator, generator.layer_128x128_vars+VAE.layer_128x128_vars))\n","    discriminator.op.apply_gradients(zip(gradients_of_discriminator, discriminator.layer_128x128_vars))\n","    \n","    return gen_loss, disc_loss\n","    \n","    \n","@tf.function\n","def train_step_256x256(images):\n","    noise = tf.random.normal([images.shape[0], noise_dim])\n","\n","    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n","        \n","        images_with_gaus = discriminator.gaus_noise(images)\n","        \n","        z, mean, logvar = VAE.model_256x256(images, training=True)\n","        \n","        generated_images = generator.sigmoid(generator.model_256x256(z, fader=checkpoint.fader, training=True)[1])\n","        generated_images_with_gaus = discriminator.gaus_noise(generated_images)\n","\n","        \n","        real_output = discriminator.model_256x256(images_with_gaus, training=True)\n","        fake_output = discriminator.model_256x256(generated_images_with_gaus, training=True)\n","        \n","        \n","        reg_loss = regulerizer_loss(z, mean, logvar, generated_images_with_gaus, images)\n","        gen_loss = generator_loss(fake_output)\n","        total_gen_loss = gen_loss + (0.1*reg_loss)\n","        disc_loss = discriminator_loss(real_output, fake_output)\n","\n","    gradients_of_generator = gen_tape.gradient(total_gen_loss, generator.layer_256x256_vars+VAE.layer_256x256_vars)\n","    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.layer_256x256_vars)\n","\n","    generator.op.apply_gradients(zip(gradients_of_generator, generator.layer_256x256_vars+VAE.layer_256x256_vars))\n","    discriminator.op.apply_gradients(zip(gradients_of_discriminator, discriminator.layer_256x256_vars))\n","    \n","    return gen_loss, disc_loss\n","    \n","    \n","@tf.function\n","def train_step_512x512(images):\n","\n","    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n","        \n","        images_with_gaus = discriminator.gaus_noise(images)\n","        \n","        z, mean, logvar = VAE.model_512x512(images, training=True)\n","        \n","        generated_images = generator.sigmoid(generator.model_512x512(z, fader=checkpoint.fader, training=True)[1])\n","        generated_images_with_gaus = discriminator.gaus_noise(generated_images)\n","\n","        \n","        real_output = discriminator.model_512x512(images_with_gaus, training=True)\n","        fake_output = discriminator.model_512x512(generated_images_with_gaus, training=True)\n","        \n","        \n","        reg_loss = regulerizer_loss(z, mean, logvar, generated_images_with_gaus, images)\n","        gen_loss = generator_loss(fake_output)\n","        total_gen_loss = gen_loss + (0.1*reg_loss)\n","        disc_loss = discriminator_loss(real_output, fake_output)\n","\n","    gradients_of_generator = gen_tape.gradient(total_gen_loss, generator.layer_512x512_vars+VAE.layer_512x512_vars)\n","    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.layer_512x512_vars)\n","\n","    generator.op.apply_gradients(zip(gradients_of_generator, generator.layer_512x512_vars+VAE.layer_512x512_vars))\n","    discriminator.op.apply_gradients(zip(gradients_of_discriminator, discriminator.layer_512x512_vars))\n","    \n","    return gen_loss, disc_loss\n","    \n","    \n","# @tf.function\n","# def train_step(images, VAE_model, Gen_model, Dis_model):\n","#     noise = tf.random.normal([images.shape[0], noise_dim])\n","\n","#     with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n","        \n","#         images_with_gaus = discriminator.gaus_noise(images)\n","        \n","#         z, mean, logvar = VAE_model(images, training=True)\n","        \n","#         generated_images = Gen_model(z, fader=checkpoint.fader, training=True)[1])\n","#         generated_images_with_gaus = discriminator.gaus_noise(generated_images)\n","\n","        \n","#         real_output = Dis_model(images_with_gaus, training=True)\n","#         fake_output = Dis_model(generated_images_with_gaus, training=True)\n","        \n","        \n","#         reg_loss = regulerizer_loss(z, mean, logvar, generated_images_with_gaus, images)\n","#         gen_loss = generator_loss(fake_output)\n","#         disc_loss = discriminator_loss(real_output, fake_output)\n","\n","#     gradients_of_generator = gen_tape.gradient(total_gen_loss, generator.trainable_variables+VAE.trainable_variables)\n","#     gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n","\n","#     generator.op.apply_gradients(zip(gradients_of_generator, generator.trainable_variables+VAE.trainable_variables))\n","#     discriminator.op.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n","    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OUKl8bb7hq5d","colab_type":"code","colab":{}},"source":["def train(base_epochs=7500, base_batchs=128):\n","    growing_model = [   (train_step_4x4, generator.model_4x4, 4, int(base_batchs/(2**0)), base_epochs),\n","                            (train_step_8x8, generator.model_8x8, 8, int(base_batchs/(2**0)), base_epochs),\n","                            (train_step_16x16, generator.model_16x16, 16, int(base_batchs/(2**0)), base_epochs),\n","                            (train_step_32x32, generator.model_32x32, 32, int(base_batchs/(2**0)), base_epochs),\n","                            (train_step_64x64, generator.model_64x64, 64, int(base_batchs/(2**0)), base_epochs),\n","                            (train_step_128x128, generator.model_128x128, 128, int(base_batchs/(2**1)), base_epochs),\n","                            (train_step_256x256, generator.model_256x256, 256, int(base_batchs/(2**2)), base_epochs)]#,\n","    #                         (train_step_512x512, generator.model_512x512, 512, int(base_batchs/(2**5)), base_epochs)   ]\n","\n","    for i in range(checkpoint.level.numpy(), len(growing_model)):\n","        (train_step, Gen_model, size, batch_size, epochs) = growing_model[i]\n","        \n","        train_dataset = resize(imgs, size, batch_size)\n","        discriminate_loss_list = deque(maxlen=500)\n","        generate_loss_list = deque(maxlen=500)\n","        \n","        for epoch in range(checkpoint.step.numpy(), epochs+1):\n","            start = time.time()\n","            gen_epoch_loss = []\n","            disc_epoch_loss = []\n","            \n","#             print(generator.fader, '/', generator.fader_total, '=', generator.fader/generator.fader_total)\n","            \n","            \n","            if epoch < generator.fader_total:\n","                checkpoint.fader.assign(epoch)\n","            elif checkpoint.fader != generator.fader_total:\n","                checkpoint.fader.assign(generator.fader_total)\n","                \n","\n","            for image_batch in train_dataset:\n","                gen_loss, disc_loss = train_step(image_batch)\n","                gen_epoch_loss.append(gen_loss)\n","                disc_epoch_loss.append(disc_loss)\n","                \n","            discriminate_loss_list.append(tf.reduce_mean(disc_epoch_loss))\n","            generate_loss_list.append(tf.reduce_mean(gen_epoch_loss))\n","            \n","            if (epoch) % 50 == 0 and (epoch) != 0:\n","                checkpoint.step.assign(epoch)\n","                checkpoint.level.assign(i)\n","                checkpoint.save(file_prefix = checkpoint_prefix)\n","                generate_and_save_images(Gen_model, size, epoch, seed)\n","                plot_graph_disc_and_gan(discriminate_loss_list, generate_loss_list, size)\n","                \n","                \n","            print ('Time for layer {}, epoch {}, fader {:.1f}% is {:.5f} sec'.format(size, epoch, (checkpoint.fader.numpy()/generator.fader_total)*100, time.time()-start))\n","        del train_dataset\n","        \n","        checkpoint.step.assign(0)\n","        checkpoint.level.assign(i+1)\n","        checkpoint.save(file_prefix = checkpoint_prefix)\n","        \n","#         generate_and_save_images(Gen_model, size, epochs, seed)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UofzdJEei1K1","colab_type":"code","colab":{}},"source":["def generate_and_save_images(model, layer, epoch, test_input):\n","    \n","    predictions = generator.sigmoid(model(test_input, training=False)[1])\n","#     print(predictions.shape)\n","\n","    fig = plt.figure(1, figsize=(7,7))\n","    plt.clf()\n","\n","    for i in range(predictions.shape[0]):\n","        plt.subplot(7, 7, i+1)\n","        plt.imshow(predictions[i, :, :, :])\n","        plt.axis('off')\n","\n","    plt.savefig(path+folder+'_imgs/image_{:01d}x{:01d}_{:04d}.png'.format(layer, layer, epoch))\n","    display.clear_output(wait=True)\n","    plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AJrU2_aeuZPV","colab_type":"code","colab":{}},"source":["def plot_graph_disc_and_gan(discriminate_loss_list, generate_loss_list, layer):\n","    plt.figure(2)\n","    plt.clf()\n","#     plt.ylim(top=1, bottom=0)\n","    plt.plot(generate_loss_list, c='g')\n","    plt.plot(discriminate_loss_list, c='r')\n","    plt.savefig(path+folder+'_graphs/image_{:01d}x{:01d}.png'.format(layer, layer))\n","    plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gb9H_mR6KtCN","colab_type":"code","outputId":"dd783afd-fcbf-440e-9cb5-c8fbc474bb56","executionInfo":{"status":"error","timestamp":1562602880072,"user_tz":420,"elapsed":7408,"user":{"displayName":"Michael Jankowiak","photoUrl":"","userId":"13749907316228325380"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["train()"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAaEAAAGbCAYAAABtSS8JAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n","text/plain":["<Figure size 504x504 with 49 Axes>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xd8FGX+B/DPk05JSCEESAIJTXqR\nklClnIrKWQE7nqDeeeqp5939OD3PCCpy6qnYCyIqIgh6oGKht1AMEkqAUFIIgZAQSO/Z7++P78xm\nk2wLJNns8H2/Xnnt7szs7DPJ5jPPPPPMM4qIIIQQwrg8XF0AIYQQTUuCXgghDE6CXgghDE6CXggh\nDE6CXgghDE6CXgghDE6CXgghDE6CXgghDE6CXgghDM7L1QUAgPbt21NUVJSriyGEEG5lz54954go\n1NFyLSLoo6KikJCQ4OpiCCGEW1FKpTuznDTdCCGEwUnQCyGEwUnQCyGEwUnQCyGEwUnQCyGEwUnQ\nCyGEwUnQCyGEwbl30G/bBjz9NGAyubokQgjRYrl30O/eDcybBxQWurokQgjRYrl30AcG8mNenmvL\nIYQQLZgxgj4/37XlEEKIFsy9g75dO36UGr0QQtjk3kEvTTdCCOGQMYJemm6EEMIm9w56aboRQgiH\nJOiFEMLg3Dvovb2BNm2k6UYIIexw76AHuFYvNXohhLDJ/YM+MFCCXggh7DBG0EvTjRBC2OT+QS9N\nN0IIYZf7B7003QghhF0S9EIIYXDuH/Tt2nEbPZGrSyKEEC2S+wd9YCBQWQmUlrq6JEII0SIZI+gB\nab4RQggb3D/o9WEQpIulEEJY5f5BLzV6IYSwS4JeCCEMzv2DXppuhBDCLvcPeqnRCyGEXU4HvVLK\nUym1Vyn1vfY6Wim1Syl1XCm1TCnlo0331V4f1+ZHNU3RNRL0QghhV0Nq9I8DOGzxej6A14moB4AL\nAGZp02cBuKBNf11brun4+fG49NJ0I4QQVjkV9EqpCAA3APhYe60ATASwQltkMYCbtec3aa+hzZ+k\nLd80lJJhEIQQwg5na/RvAPgHAJP2OgRAHhFVaa9PAQjXnocDyAAAbX6+tnzTkaAXQgibHAa9UmoK\ngGwi2tOYH6yUekgplaCUSsjJybm0lenj3QghhKjHmRr9aAA3KqXSAHwFbrJ5E0CgUspLWyYCQKb2\nPBNAJABo89sByK27UiL6kIiGEdGw0NDQS9oIqdELIYRtDoOeiP5JRBFEFAXgDgAbiOhuABsBTNUW\nuw/AKu35au01tPkbiJp4aEkJeiGEsOlS+tH/H4C/KqWOg9vgF2rTFwII0ab/FcDsSyuiE6TpRggh\nbPJyvEgNItoEYJP2PAXACCvLlAGY1ghlc57U6IUQwib3vzIW4KAvKeFx6YUQQtRijKCX8W6EEMIm\nYwS9DIMghBA2SdALIYTBGSPopelGCCFsMkbQS41eCCFskqAXQgiDM0bQS9ONEELYZIyg9/fn4Yql\nRi+EEPUYI+g9PLhWL0EvhBD1GCPoARnvRgghbDBO0Mt4N0IIYZUEvRBCGJxxgl6aboQQwirjBL3U\n6IUQwioJeiGEMDjjBH27dkBBAWAyubokQgjRohgn6AMDASKgsNDVJRFCiBbFWEEPSPONEELUYZyg\nl/FuhBDCKuMEvdTohRDCKgl6IYQwOOMEvTTdCCGEVcYJeqnRCyGEVcYJer1GL0EvhBC1GCfovb2B\n1q2l6UYIIeowTtADMgyCEEJYIUEvhBAGZ6ygl6GKhRCiHmMFvdTohRCiHgl6IYQwOGMFvTTdCCFE\nPcYKer1GT+TqkgghRIthvKCvrARKS11dEiGEaDGMFfQy3o0QQtTjMOiVUn5Kqd1KqX1KqSSl1PPa\n9Gil1C6l1HGl1DKllI823Vd7fVybH9W0m2BBxrsRQoh6nKnRlwOYSESDAAwGMFkpFQtgPoDXiagH\ngAsAZmnLzwJwQZv+urZc85CgF0KIehwGPbEi7aW39kMAJgJYoU1fDOBm7flN2mto8ycppVSjldge\naboRQoh6nGqjV0p5KqUSAWQDWAvgBIA8IqrSFjkFIFx7Hg4gAwC0+fkAQhqz0DZJjV4IIepxKuiJ\nqJqIBgOIADACQO9L/WCl1ENKqQSlVEJOTs6lro5J0AshRD0N6nVDRHkANgIYCSBQKeWlzYoAkKk9\nzwQQCQDa/HYAcq2s60MiGkZEw0JDQy+y+HVI040QQtTjTK+bUKVUoPa8FYCrARwGB/5UbbH7AKzS\nnq/WXkObv4Goma5gatWKx6WXGr0QQph5OV4EnQAsVkp5gncMy4noe6XUIQBfKaVeALAXwEJt+YUA\nPldKHQdwHsAdTVBu65SS8W6EEKIOh0FPRPsBDLEyPQXcXl93ehmAaY1Suosh490IIUQtxroyFpAa\nvRBC1CFBL4QQBme8oJemGyGEqMV4QS81eiGEqEWCXgghDM54Qd+uHVBSwuPSCyGEMGDQ68MgSDu9\nEEIAMHLQS/ONEEIAMGLQy3g3QghRi/GCXmr0QghRiwS9EEIYnPGCXppuhBCiFuMFvdTohRCiFuMF\nvb8/D1csQS+EEACMGPQeHkBAgDTdCCGExnhBD8gwCEIIYUGCXgghDM6YQS9DFQshhJkxg15q9EII\nYSZBL4QQBmfMoJemGyGEMDNm0AcGctCbTK4uiRBCuJxxg54IKCx0dUmEEMLljBv0gLTTCyEEjBr0\n7dvz47lzri2HEEK0AMYM+g4d+DE727XlEEKIFkCCXgghDE6CXgghDM6YQd+mDdCqlQS9EELAqEGv\nFNfqJeiFEMKgQQ9I0AshhEaCXgghDE6CXgghDM74QU/k6pIIIYRLOQx6pVSkUmqjUuqQUipJKfW4\nNj1YKbVWKXVMewzSpiul1AKl1HGl1H6l1JVNvRFWdegAVFQABQUu+XghhGgpnKnRVwF4ioj6AogF\n8IhSqi+A2QDWE1FPAOu11wBwHYCe2s9DAN5r9FI7Q/rSCyEEACeCnojOENFv2vNCAIcBhAO4CcBi\nbbHFAG7Wnt8E4DNiOwEEKqU6NXrJHZGgF0IIAA1so1dKRQEYAmAXgDAiOqPNygIQpj0PB5Bh8bZT\n2rTmJUEvhBAAGhD0Sqm2AFYCeIKIajV8ExEBaNBZT6XUQ0qpBKVUQk5OTkPe6hwJeiGEAOBk0Cul\nvMEhv4SIvtEmn9WbZLRHPVEzAURavD1Cm1YLEX1IRMOIaFhoaOjFlt82fahiCXohxGXOmV43CsBC\nAIeJ6L8Ws1YDuE97fh+AVRbTZ2i9b2IB5Fs08TQfHx8gKEiCXghx2fNyYpnRAO4FcEAplahNexrA\nywCWK6VmAUgHMF2btwbA9QCOAygBcH+jlrgh5KIpIYRwHPREtA2AsjF7kpXlCcAjl1iuxiFBL4QQ\nBr4yFpCgF0IISNALIYThGT/oc3OBqipXl0QIIVzG+EFPxGEvhBCXKeMHPSDNN0KIy9rlEfRnz7q2\nHEII4UKXR9BLjf7SFRYCkyYBhw65uiRCiAZy66DflLYJT/z0BMjWzUUk6BtPYiKwYQOwdq2rSyKE\naCC3Dvp9Wfvw5q43cb70vPUFAgMBLy8J+saQmsqPJ0+6thxCiAZz66Dv7N8ZAJBZWG/MNObhAYSG\nStA3Bj3o09NdWw4hRIO5ddCHB/Aw95kFNoIecO6iqTNngB49gH37GrF0BpOSwo8S9EK4HbcOer1G\nf7rwtO2FnAn6nTuBEyeAVavsL3c5k6YbIdyWIYLeZtMN4FzQHz3Kj9u3N1LJDEgP+uxsoLTUtWUR\nQjSIWwe9j6cPQluHXnqNXg/6HTuA6urGK6BRlJcDmZlA9+78Wmr1QrgVtw56gGv1Dmv0xcX8Y4se\n9IWFwMGDjVtAI0hP56Ekxo/n1xL0QrgVtw/68IBwxydjAcDefWmTk/liIECab6zRm20mTOBHOSEr\nhFtx/6D3D3fcdAPYbr65cIF3AtdeC3TsCMTHN34h3Z3e42bMGO6yKkEvhFtx+6Dv7N8Z2cXZqKyu\ntL6Ao6A/dowfr7gCGD266Wr0GzcCSUlNs+6mlpoK+PoCkZFAeLg03QjhZtw+6MP9w0EgnCmycf9x\nR0GfnMyPvXpx0KelAaftHCFcjKIi4Pe/B555pnHX21xSU4GoKK7Nd+kiNXoh3IzbB73DvvShofxo\nK+iPHgU8PYFu3Tjogcav1S9fzieD9SYQd5OaCkRH8/OuXSXohXAzbh/0Dq+ObdOGf+wFfXQ04OMD\nDBkCtGrV+EG/cCE/pqRw7xV3k5LCO0KAg/7UKemGKoQbcf+g9+egv+i+9EePcrMNAHh7AyNGNG7Q\nHz7MJ3ijorhWf+5c4627OeTn8wlrvUbfpQvfmvGMjaYyIUSL4/ZBH9I6BN4e3hd3dazJVDvoAW6+\n2bvXfr/7hvjkEx5B8+mn+bXeVdFd6OW1bLoBpPlGCDfi9kHvoTycu2jKWtCfPg2UlNQP+upqYPfu\nSy9cZSXw2WfAlClAbCxPc7d2er28EvRCuC23D3qAT8heVNONfkXsFVfUTBs5kh8bo/nmhx/4c2fN\nqgnKllKjr6jggdwc0curt9F36cKP0sVSCLdhiKB36urYnBxuqrGkB71ljT4oCOjXr3GCfuFCoFMn\nYPJkoG1b7gHkyqAnAhISgL/8hfvD9+zp+NaAqal8A5fAQH7dti0QHCw1eiHciDGC3pmrY6uqgLy8\n2tOTk4HWrYHOnWtPHz2aBziru2NoiNOngTVrgD/8gdvoAa7VuyLoMzOB+fOB/v2B4cOBDz/kpiQi\nYMsW++9NSak5GtFJF0sh3Iohgr6zf2cUVhSisLzQ+gK2Lpo6epRrtR51fg2jR3Nvk0u5knXxYt5R\n3H9/zbTo6OZvo9+0iZtbZs/mo5UPPgCysoDVq/kIY9cu++9PTa1pttF17SpNN0K4EUMEvd7F0uYJ\nWXtBb9k+r7vUC6eIuLfNuHG8I9FFR3NANmcf9B9/5COKo0eBbduAhx7iZhiluFa/c6ft95pMfKVw\n3Rq9fnWsO14TIMRlyBhBH+CgL721oK+o4NqqZfu8rls3ICzs4oN+61bg+HE+CVt3vVVVfMFRczly\nhG+TaLnD0cXE8Py6TVq6rCygrMx6001REfevF0K0eIYIevOdpmydkLUW9CkpXLO2FvRKXdoAZwsX\nAv7+wNSptae7oufNkSNA797W5+ldPm11Ja3b40and7GU5hsh3IKhgt5mjb59e360DHprPW4sjR7N\nQdfQK0Dz84GvvwbuvJNP9FrSg7652ukrK/mzrDVPAXxiVinb7fR1L5bSSV96IdyKIYK+rU9bBPgG\n2G6j9/ICQkIaHvRAw2v1X33F91St22wDcNu2h0fz1ehPnOCmIls1+oAAoE8f20Gv75D0YNfpfekl\n6IVwC4YIeoBPyDbo6tjkZO51EhRkffkhQwA/v4YH/Sef1HRjrMvbm8d0b66g14dgtlWjB2pOyFo7\nsZqayv3t/fwAAFlFWSAi/r21aiVNN0K4CeMEfYATfenr1uht1eYBHs2yoQOcnT/P7d23385NItY0\nZ1/6I0f40V7Qx8QAubnWm5MshidOy0tD5OuR+OHYD7xtMi69EG7DYdArpT5RSmUrpQ5aTAtWSq1V\nSh3THoO06UoptUApdVwptV8pdWVTFt5SZ//Ojq+OtRH050rOYeyisTiWe6z2e/QBzkpKnCuE3lVx\nzBjbyzRnX/rkZL49on5VqzUxMfxorZulxcVSu07tQpWpCnvP7OV5EvRCuA1navSfAphcZ9psAOuJ\nqCeA9dprALgOQE/t5yEA7zVOMR0L9w/HmaIzMJGNq1ktg76ggLsOajXdbSe3YdvJbVhxaEXt94we\nzW3cv/7qXCHi4/kmJtaabXTduvFnl5Y6t85LceSI/do8wMM9tGlTv52+ooK7gWo9bvZmccCfuKCN\njyNXxwrhNhwGPRFtAXC+zuSbACzWni8GcLPF9M+I7QQQqJTq1FiFtaezf2dUmaqQU5xjfYEOHbjf\nd0VFvROxB7P5YGXrya213zNqFDdTbN7sXCHi44HBgzk4bdF7sKSlObfOi0Vkv2ulzssLGDasfo3+\n5Eleh1bexKxEAHWCPju7eXZYQohLcrFt9GFEpPc7zAIQpj0PB5BhsdwpbVqTc/rq2HPn6gV9Ug4P\ndRCfEY9qk8VVq0FBfFJ240bHBaiq4lrxqFH2l7vULpY5Oc6NOnnuHO/YHNXoAT4hm5jIF0fp6gxP\nbA7689pn6z1vMiz/3EKIluiST8YSEQFo8LXwSqmHlFIJSqmEnBwbtfAGaNDVsUePck29e3cAQFJ2\nErw9vJFfnm+u3ZtNmMA1dUc11/37uS3fUdDrFx819IQsEY9t36sXB7OjAdf0E7F2avTmnVpMDPe5\nT0ysmWlxsdSZwjM4W3wWndp2wpmiMyiuKHZ9X/r8fGDZMv65lMHnhLgMXGzQn9WbZLRH/SxnJoBI\ni+UitGn1ENGHRDSMiIaF6jfwvgQNujr26FG+tZ+fH6pMVUjOTcatfW4FwO31tUycyM098fH2C6DP\ndxT0YWHcNbEhQZ+ZyTcvue8+wNeXa+uHD9t/j4OulZvSNsF/nj/S8tKsn5BNTeWeR507m2vzt/S+\nBQCQciHFNVfHZmYC773Hwz6HhgJ33ME/o0bxSXNXIuIeVy+95PqyCFHHxQb9agD3ac/vA7DKYvoM\nrfdNLIB8iyaeJtWxbUcoKOcGNktONjfbHD9/HBXVFbih5w0I9w+v304/diyfYN2wwX4B4uO5z3lk\npP3llOKdjDNBrw+O1q8fNx+9/npNM5K9wcgArtH7+ta/2EnzzeFvUFpVinUp63iY5sjI2idkU1P5\nvR4e5hOx+s7wxIUTvK0eHs1To1+xgndGERHAn//MzUpPPMFdXz//nMs6bBhPKyho+vJYSkoC/vUv\nHksoJgZ45hlg6FDg4Ye526qrVFUBv/wCPPAAX6Xt6L4DzaW8nP+XXPm7uQw5071yKYAdAK5QSp1S\nSs0C8DKAq5VSxwD8TnsNAGsApAA4DuAjAH9uklJb4eXhhbC2YY6bbs6erdW1Um+q6dehH8Z2HYut\nJ7fyRUE6f3/uT+9M0I8ebbv/vCVnulhmZgLXXcdX2A4axE1DTzzBTTFBQY6DXt+ZeXpanb0+dT0A\nYHuGdp1ATEztdVp0rUzMSkS3oG64shP3lj1x/gRf/NW5s+2gJ+IAnDePt+ViLV0KTJ/OzWIvvcSB\nlZwM/Oc/XJO/5x7eqT30ELBgAV/pu3x5046sWVEBvPoq/1369+dtjI7mMY5SU/nGLh99xL//999v\nvtFKq6t5WOqHH+Yb3lx7Lf8ufvwRGDiQy3W+br+KZnLgAH9/w8OBSZP4d/PBB807kqs1lZU8COGa\nNcZuAiQil/8MHTqUGsPQD4bS5C8mW59pMhF5exPNmEEEEL31FhERxW2MIxWnqLiimN7e9TYhDpRy\nPqX2e595hsjTk6igwPq6T53idb7xhnMFffRRooAALpMtU6YQtW7N5ayurj3vuuuI+ve3/xk9ehBN\nnWp1VmZBJiEO5PG8B/VY0IMnvvIKb8PZs/w6JIToT38iIqKeC3rSbctuIyKioJeD6OHvH+ZlRo8m\nGj/e+ufHx/P6ACIPD6LrrydasYKovNx+uS2tWsW/96uuIiopcbz8zp1EQ4bwZ157LdHx485/lrNK\nSohuuIE/Y+RIogULiM6cqb/c/v38uwG4TNu3N35ZLL31FlHHjvx5rVsT3X470TffEJWWEuXkED38\nMP8dgoOJ3nmHqLKyactDRJSfT/TBB0QjRnC5fHyIpk8nWrqU/6YA0dChRLt2NX1ZLJ06RfTxx0S3\n3UbUrl3N93T48Kb/OzUyAAnkRMa6POSpEYP+xqU30sD3BtpeIDycKDqaN/uXX4iIaNryaeaw25e1\njxAH+izxs9rvW7+e3/PDD9bX+/XXPH/3btqZsZPOFFr5x7f02mu8fG6u9fklJUR+fkR/+Yv1+c8/\nT6QUUV6e9fllZRyQ//qX1dmf7/ucEAe6e+XdhDhwebdu5TKtXs3/oADR/PlUUFZAiAPN3TyXiIiG\nfTiMrvn8Gl7RXXfx79Oau+/mnVliIu8ow8N5ne3bEz3xBNHRo7Z+O2zdOiJfX/7ny8+3v6ylykre\n4fr78/vnzOHfhz1lZc7tFAoKOLyV4gBzxGQi+uoroogI3vZ77uGQaUwmE9E//8nrnzCBP6+oyPqy\n+/bxMgBXFNavb9yyWFq7lv/++me98QbvcCzLvWQJUadO/Pt84IHa85vC8uVEAwfWBHt4OH/uypVE\nixcTde7M0++4gyg9vWnL0kguy6D/03d/opD5IbYX0Gt7AFFaGhER9X2nL9209CYiIqqqrqJ289rR\ng6sfrP2+khIOjaeesr7eJ58katWKSksKqNULrWjWqln2C/rNN1yGhATr83/6ieevWWN9/s8/8/y1\na63PT0ri+Z9/bnX2fd/eRyHzQ2j7ye2EONCKpBVExcW8c3j6aQ5ngGj5ctqWvo0QB/ou+TsiIrr9\n69up+5vdeUWzZxN5eRFVVdX+gLNnufZmuaOqqiL68UeiadN4nqcn/5OdPFm/gPHxRG3acECcO2d9\nGx05dYo/CyDq1at+qJlMvHN76CGiwEBe7oYbbO+AcnO5ZurpSfTFFw0rS1ER/159fXm7XnyRa9rW\nmEx8ZPLkkxyO9o6Aqqr4qAvg7aj7d7C1/pUriaKi+H3Tpzf+zufbb/lvPHAg19btHbnm5/P/lZcX\nUVAQ0Ucf2V/+Yi1ZwjuUQYOI5s/nI666n1NURPTvf3Mly8+P6NlniQoLG78surIyPrpPTb3oVVyW\nQT9381xCHKi00sY/0bXX8ib7+hJVV1N5VTl5zfGip9c9bV7k+iXXU5+3+9R/74QJvKOwJiaGaNw4\n2pK2hRAH6++3ZBGkVj3xBJexuNj6/Lw8/tLOnWt9vr4j+fXXerNMJhNF/DeCpi2fRuVV5eT3gh89\n+dOTPPPKK4kmTeJ/VG1HpDdnncrnMHh63dPkNceLKqsrid57j5erGxQvvsjTDx+2Xr6sLKLHH+cw\n8PHh7dWbjPbu5eDt0YPo9Gnr72+IH38k6t6dy3PXXRyizz5bc2TXujXXtJ97jo8CvL2J/vGP2s10\nWVkcWj4+/Lu5WCdOEN16K39uVBQ3Zelhk55O9MILvFMCuBwAUe/efHRTV0UF1zwBov/7v4aHY2kp\nH+34+fHO5z//sb1TOXOGm4ZmznTczPLZZ7wzjI0lOn/e+fIkJdU050yc2LjNbl99xc1W48fb/p+y\nlJ5OdOedXJZOnbiZx5mdaEPk5dUcXX300UWv5rIM+k9++8R6G7vu3nvJfChJRAfOHiDEgZbsX2Je\nZN7WeYQ4UE5xncPIuXM5XOvWMEtK+J9y9mzzjgZxoAulF2wX1KJpxKrevXmnZE/fvlwDteall3j9\nVs4pHMk5QogDvf/r+0RENG7ROBr+4XCe+fDDHHZ6e31uLs1aNYva/6c9mbQgWfjbQkIc6MT5E3zE\nAdRu16ysJIqM5B2GI+npHB4eHkRt2xL97W9EoaH8fu2Iq1GUlHC4+/iQ+ZzB1VdzKFnW2M6cIfrD\nH3iZjh35cD49ncO3dWtzc98lW7+ev4MAh5v+D6+/XriQvyPff0/UrRtPnzat5uinuJjPeQBEL798\naWU5cYLo97/ndfXpQ7RhA0/PyeHmqYkT+fcFELVqVbPDtNa08fbbPH/SpIurCVdX82cGBPBnvfaa\n9YAtKeHKzIwZ/J3Jzra9zhUreMczdmzDy7R9O++w9MxYs8b2DrWykv+ur7xClJFhf70ZGUQDBvBR\njI2jbmddlkH/07GfCHGgrelbrS/w1FO8ybfxicWvDnxFiAPty9pnXmRr+lZCHOjbw3Vqbtu383tX\nrqw9fcsW0tu2r/7savKa40WIA/1y3EEoBAebT3bWkprK63v9dfvvnzmTT5ha++LNmMHtjVa8s/sd\nQhzoeC7XmJ5e9zR5Pu9JReVFRJ9+WlOj0k4WD/1gKP3us9+Z378pdRMhDvTz8Z9rmoi+/LLmA/Sj\ngW++sV9+S4cP1zSzdOhAlJzs/HsbIjmZQzQz0/5yO3fWPoEYEEC0bVvjlqWykujdd/mcRY8eXLtO\nsVJBsax5t27NR0tjx3Kl4/33G688q1fXHOVceSWHkN7s9e9/89+6oIDP++hNG//8J++QTKaao7ib\nbrLdLOWsjAzujADw3+HAAW5WWb6cm5ratOF5wcEc4v7+/DuqG+T/+x9vx6hRtjtSOGIy8Tk4/ahw\n0iSiPXt4Xmkp/97uv5/Lou+sW7Xi35O1zzx4kM/Z+PvbbnptgMsy6PUa+rKDy6wvMH8+b/I//0lE\nRM9ueJY8n/ekssqak3VllWXkO9eXnvq5Tnt8RQV/wR55pPb0l18mAqgi6zS1ebEN3fvNvaTilPnk\npU1DhxJdc0396e+/T3abPXQffsjLWWtTjonhsLbi1mW3UtfXu5pr6GuOriHEgTakbCA6coTXqRTR\n4MFUUVVBPnN96O+//N38/oz8DEIc6N3d7/I/Vt1a5dVX8xf5Ynp1HDzYck6CVVfzjm/ixJp/7KZg\nMjnX7JKaSnTzzfz79vLi5ojGVlLCTVhDh3Jz0N691st28iQ3d+k75unTyXyyuaKiccpiMnHvnPbt\n+YhZP5ro0IErSOvW8Xfs8GGiW27heWFhvPOsqOCjIW9v3lE05GS+LeXlRG++yZUrgHe2bdvy84AA\n7nywciXRoUM1zT5hYXyEov8vbNrEvXw6deLfbSO4LIM+tySXEAf6b/x/rS+waBFv8qJFRMShd8Vb\nV9RbbMwnY2jERyPqv3/yZD68tXTjjUS9etHOjJ2EONDXSV9Tn7f70A1LbDSr6KZNI+rZs/70m28m\n6trV8T//gQO8LZ/V6SFkMvGX6eGH672lqrqKAl8OpJn/m2medqH0Aqk4RXM2zeFw009M3nIL7c/a\nX69pq9pUTX4v+NXsCIODaz4rOZnfa+vcgbh0GzbwyeqWYPduDjyAvwN1uwE3hpwcosce45/Nm223\nlcfH15Sle3c+Ehs6lOiCnSbUi5GXx50QevfmE+A//WT93MbOndz9GCDq14+POHx8+H2N2CzpbNAb\n5sYjABDkFwQ/Lz/bV8f26MGWgUZdAAAZqElEQVSPgwcD4Iul+nXoV2+xsV3G4rczv/GYLpYmTuSh\nB/T7yBLxhVKjRmFL+hbze2MiYrArcxfvSW2JjuaLjSwv0qioANav50v8HV141acPX8xV98Kp7Gwe\nB8bKGDd7s/YirywPv+v2O/O0QL9A9O/QH9sytvGVriNGmMunD30wuONg8/IeygPdgrpZH6743Xf5\nQqoHH7RfdnHxJkwARo50dSnY8OE8suvRo8A77/D3p7G1b88Xwi1YAIwbZ/MCQIwcyWX5/nsePXbQ\nIL4y2N69GC5Gu3Z8gdzhw3zB17XX8lAhdcXE8IVYK1bwYIH//nfNjYxsXK3elAwV9EophPvbudPU\nmDF8xefgwSirKsPx88fRL7R+0I/pMgZVpirsyqwzRvvEifyoD0Nw/DiPOzNqFDanb0bv9r0R1jYM\nseGxOFdyjseEsSU6moP9tEVZd+wACgs56B3x9OQvzo4dtafbuavUupR1vBnRE2tNH9NlDHZk7OBB\nzmJjeWK3btibtRd+Xn7oFVL7Tlzdg7rXHsUyPR0oLgY+/RSYOpXH8xGXB6V4+AdnrghvjrLccAOw\nbx8P5xEc7Pry3HYbX839ww/A2rUuK5Ohgh7Q7jRl796x2mX9yeeSYSIT+nfoX2+RUZGjoKDqD3A2\neDDXEPSg1wYyq46NwbaT2zCuyzgAQEwEDxJWb0dhSR/F0nIohB9/5PHhJ060/p66YmN5aIRiiyMP\nfTAzKzX69anrMaDDAIS1rR3EY7qMQWFFIQ5kH6gZlK1nTyRmJWJg2EB4eXjVWr57UHekXEjhIxa9\nRr9kCR9JPPKIc2UXoim1hB2PzscHuP56872XXcFwQe/w3rEafQx6azX6QL9ADAwbWH+AM09PYPz4\nmnFv4uOBdu2wP7gS+eX5uCrqKgBA/w790dq7NXadshP0+rj0loOb/fQTj5cTEOCw/AA46KurgT17\naqYdOcKjY9YZXK2sqgzbTm7DpOhJ9VYzOnI0AG3kzmuuAdasAU2ahMSsRAwOG1xv+e7B3VFcWYyz\nxWc56IuKeOyZQYMcj94phGh2hgv6zm353rF228fB7fNeHl7oGdLT6ny9OaPKVFV7xsSJXAtPS+Og\nHzkSWzK45j+uK9fovTy8MKzzMOzMtDPwWJcuXOvQg/70aT7kdKbZRqc3s1i20x85wgNG1Wkvjc+I\nR1lVWa32eXNR2nVBREAED3CmFHDddThZeAoXyi7Uap/XdQ/icfxPnD9R09544gSPLNmSalJCCAAG\nDPrwgHCUVpUiryzP7nJJOUnoFdILPp5WTqSAT6oWVxabT0ia6c0q337LQ9SOHo3N6ZvRLagbIgIi\nzIvFhsciMSsR5VXl1gvg68sj+elB/8sv/NiQoG/fnk8wW7bTJydbb7ZJWQ8vDy/zzsiSUgpjuozB\n1vSakTv17R7SaUi95bsHc9AfP3+85k5T7doBd9/tfNmFEM3GeEHv7+BOU5qk7CSr7fO6MV3GALBy\nI5K+fXnI49deA4hAI0diS/qWegEaExGDiuoK81juVnXrVtNG/9NPQMeO3PzRELGxXKMn4rP7qanW\nT8SmrsOI8BHw9/W3uprRkaORWZiJk/l8I5HErEQoKAzoMKDeslGBUfBQHtzzJjqaa/F/+IP9e+UK\nIVzGcEFvvtOUnROyJZUlSLmQYrV9XhceEI7owOj67fRKca0+MxPw8MCRbgHILc01n4jVxUZws4rD\ndvrUVG5n/+UX7qrV0KaP2FggK4vv9HT8OAd+nRp9XlkeEk4n4HfR9ZttdPqOTR+ffm/WXvQK6YU2\nPvXD28fTB5EBkRz07dtzl9AXX2xYuYUQzcZwQa/fO9bmLQUBHM45DALZDXoA9ZozzPTmm0GDsOlc\nAgCYT8TqOvt3RkRAhP12+uhobpvfupVv5N2QZhud3qd6506bXSs3pW2CiUyY1K3+iVjdgA4D4O/j\nbz6CScxKtNpso+sR3KOmi+WECVKbF6IFM1zQd2rbCYD9phtzjxsrF0tZGttlLHJKcnDs/LHaMyZM\n4Eet/3y4P9f+64qNiLVfo+/WjWvgH3zAJ0+vvto8Kz0vHUnZSXbLBwAYMIB72ezcWdO1slftfu/r\nU9ajtXdr81GGNZ4enhgZORLbTm7D+dLzSM9Pt9rjRtc9qHvNRVNCiBbNcEHfyrsVglsF2226ScpO\ngo+nD3oE97C7rrFdxwIAvjzwZe0Z3bsDr78OeuwxbEnfgquiroKy0uQSEx6D1LxUZBdn15sHoKaL\n5cqVfPFTSAgAHpZi2tfTMO7TcSgod3APVG9vvl/qjh1co4+MBNq2rbXI+tT1GNd1nM0Tz7oxkWNw\nMPsgNqdtBgCrPW503YO741zJOcflE0K4nOGCHoD9q2PBNfre7XvXuxCort7te2N6v+l4ceuL2HPa\noq+6UsATT+BEqCfOFJ2p1z6vc9hOrwd9ZWWtZpvdmbvx6+lfcb70PN7e/bbdMvIHxQJ79/LFU3Wa\nbTILMnH43GGr/efrGtNlDAiE9xLeA+Ag6C27WAohWjRDBr2jq2OTcpIcts/r3rvhPYS1CcPd39yN\nksqSWvP0mm/d9nndlZ2uhKfyxM5TNtrpO3XibpZAraB/+9e34e/jjwlRE/DajtdQWF5ov5AjR/Jw\nCvv31zsR+8X+LwDAqaAfET4CnsoTa1PWolPbTvWuoLWkd7GU5hshWj5DBn24f7jNk7FFFUVIy0tz\nOuiDWwVj8c2LkZybjL//8vda87ac3IIObTrgipD63RkBoLV3awzqOMj2UAgeHkBUFI9/MWwYAOBs\n0VksO7gMfxj8B7z8u5edq9XHxNQ8t6jR/3z8Zzyz4RlM6TXFbu1c18anDa7sdCUA+7V5oKZGf/z8\ncYfrFUK4ljGDPiAcZ4vP1r+qFcChnEMAHJ+ItTSp2yQ8Gfsk3k14F2uOrTFP35y2GeO6jrPaPq+L\nCY/B7szdPGCYNbNmAbNnm0fl++i3j1BpqsQjwx/BiPARuK7HdY5r9Z0711y4pNXok7KTMH3FdPTr\n0A9f3vql3TJa0rtZDulou8cNAPj7+iO0dag03QjhBgwZ9BEBETCRCT8c/aHePL0ni72Lpax5adJL\n6N+hP2aumomc4hyk56UjPT/dZvu8LjYiFoUVhThy7oj1Bf7+d/4BUFldifcS3sM13a/BFe25Zv7c\nVc8htzQX7/z6jv0C6sMhXHEFsouzMWXpFLT2bo3v7/ze5kVS1uhB78wRQPdg6XkjhDswZNBP7TsV\nQzoOwa3Lb8Vbu96qNS8pJwl+Xn5Wu0Pa4+flhyW3LsGFsgt48LsHzePP22qf18WEOzGSpeZ/R/6H\n04Wn8ejwR2veHxGD63pch1fjX0VRRZHtN997LzBlCsrCQnDzVzfjbNFZrL5jNSLbRdp+jxW/7/V7\nvH3d27jxihsdLtsjuIchgp6IUFpZ6upiCNFkDBn0wa2CseX+LZjSawr+8tNf8OiaR83NOAezD6JP\n+z7w9LBxAwM7BoYNxLxJ87AqeRX+tfFfCPILcnhk0DOkJ4L8gmyfkLXw9q9vIzowGtf3vL7WdHOt\nfredWv2UKaDVqzHzuwew49QOfHbLZxgePtyp7bLk7emNR0Y8Al8vX4fLdg/qjoz8DNvj+bRw2cXZ\neC3+NfR7tx/azmuLh757CGeLzrq0TJkFmXg1/lXEfhyL21fcjtQLqY7f1AxyinOwIXUDKqsrXV2U\nFut04Wl8l/xdvU4bLYH9/oVurK1PW3wz/RvMXjcbr+54FScunMBXt32FpJwkjI8af9HrfSL2Cfxw\n7AdsSN2AG6+4ER7K/r7SQ3lgRPgIhzX6/Wf3Y0v6Frxy9Sv1dkIxETGY3GMyXt3xKh4Z8Qja+rS1\nuo45m+dg6cGleGniS5jad2rDNuwidA/qDgIhLS/N3NSkK60sxS3LbkFeWR6ig6IRHaj9BNU8Ovrd\nNYUqUxV+Pv4zFu5diO+OfocqUxVGRozE/YPvx6LERfjq4Fd4ZuwzeDz2cfh5Nc/44XlleVh5aCWW\nHFiCTWmbQCAM6TgE3x/9HquOrMI/Rv8Ds8fMRmvv1s1SHl1BeQH+d+R/WHpwKdaeWItqqkavkF54\naeJLuLXPrU6f92kqx3KPwd/XHx3bdnRZGU4XnsbKQyux/NBybD+5HQRCuH845k6YixmDZlxUhbJJ\nOHO/wab+aax7xtry0Z6PyGuOF/V+uzchDjRv67xLWl9GfgZ1fq0zffLbJ04t/9zG58jjeQ8qLC+0\nucyDqx+kVi+0otySXKvzd2TsIMSB5m+bX29eel46/fWnvxLiQPd9e5/5xt9NbfvJ7YQ40A9Hf6g3\n76mfnyLEga5adBV1e7Mbec3xIsTB/BP530h6dsOzlHI+pVnKmlmQSc9tfI7CXwsnxIFC/xNKT/38\nFCVlJ5mXST6XTL//8veEOFD0G9H0ddLXTfa7NJlMtCFlA01bPo185/oS4kA9FvSg5zY+R8nnkomI\nv2d3rrjT/PtadnBZk/9tSytLaUXSCrp12a3mckW9EUWz186mz/d9Tv3e6UeIA8V8FEOb0zY3aVnq\nMplMtC9rHz274Vnq+05fQhzIZ64PPfrDo5RZkNls5cguyqYFOxfQmE/GkIpThDhQ/3f70/Obnqdv\nD39LMR/FEOJAA94dQD8e+7FJ/2a4HG8Obs/6lPUU+HIgIQ70XfJ3l7y+hvzx1hxdQ4gDbUzdaHV+\nbkkutXqhFT2w6gG767n282up/X/aU1F5EZlMJtqStoWmLp9Kns97ksfzHnTPN/dQeZWVGxU3kazC\nLEIcaMHOBbWmb0vfRipO0R+/+6N5WmV1JaVdSKONqRvpw4QP6drPrzX/k0xcPJG+2PcFlVSUNGr5\nTCYTbU7bTNO/nk5ec7xIxSma/MVkWnlopd3f07oT62jAuwMIcaBRC0fRq9tfpR0ZOxrld1tQVkDv\n7n7XHFTB84Pp8R8fp92ndtv8Tm1J20KD3x9s3nGuPbGWCsoKLrkslhLPJNJjax6j4PnBhDhQ2Cth\n9Niaxyj+ZHytclVVV9HC3xaad5hTvpxCB88ebNSyWDKZTLTn9B6avXY29VzQkxAH8njeg8Z/Op4W\n7FxAD65+kLzmeJHfC3705E9PUlZhVpOUo9pUTT8f/5mmLp9K3nO8a4X7oexD9cq8/OBy6v5md0Ic\naNLiSbTn9J4mKZezQa/IwQ06msOwYcMoISGhyT8n+VwyFiUuwnNXPYdW3q2a/PN0uSW5aP9Ke8wZ\nPwfPXvVsvfmvxb+Gv639GxL/mIhBHW0PU7wjYwdGfTIKt/e7HUdzj2Jv1l4E+QXhwSsfxJ+H/xld\nA5v3psNEBP95/pg1ZBbevO5NAEBxRTEGfzAYVaYq7P/Tfrs9fjLyM/Bp4qdYlLgIqXmpaOfbDmO7\njuWLtdqEoWPbjghry4/+Pv61mgoUap6byAQTmUAg8/O9Z/binV/fwYHsAwj0C8TMwTPx8PCHHQ57\noas2VWPh3oV4Jf4V87UCvp6+GB4+HKMjRyMmPAYBvgHw9PCEp/KEh/IwP1dKmcunPy+rKsPSg0vx\naeKnKKwoxNBOQ/HoiEdxe7/bnfouVpuq8fFvH+OZDc8gtzQXCgp9Q/tiRPgI80+P4B7w9vCuVSZ7\nzSv5ZflYenApFu5diITTCfDx9MEtvW/BzCEzMTF6ot0rx0sqS7Bg1wLM2zYPBeUF6NO+D0ZFjsLo\nyNEYFTkKvUJ6XVLTTsqFFHx54EssObAER84dgafyxMToiZjadypu7n0zOrTpUGvZuVvm4rN9n8HP\nyw+PDn8UM4fMREjrELTzbQdvT++LLkdGfgYWJS7CJ3s/QXp+OkJahWDGoBmYOWSmw/NzFdUVeD/h\nfczZPAe5pbno074PJkRNwIToCRgfNR7tW7e/6HLplFJ7iGiYw+Uup6B3pWEfDsOeM3swpssY3D/4\nfkzrOw3+vv6oNlWj51s9EREQgS33b3G4nslfTMbPJ35G39C++MuIv+CegfdYHUq4uQx6fxAiAyLx\n/V3fAwAe//FxLNi9ABtmbMCE6AlOrcNEJmxO24xFiYuw/+x+ZBVlIackByYyXVrZwgbh0RGP4q4B\nd11S+/aZwjOIz4hHfEY8tmdsx29nfkOlqeEnJX08fTC933Q8OvxRjAgfcVFBWFheiO0Z27E7czd2\nZ+7GrsxdOFdyzubynsoTXh5e5h9vT29+9PBGTkkOyqrKMDBsIGYNmYW7B9yNkNYhDSpPbkkuPv7t\nY2w9uRXxGfG4UHYBABDSKgSxEbEIbROKVl6t+Me75tHfxx/+vv4I8A0wP/fz8sP6lPVYcmAJdpzi\nm+mM6zoOdw+4G7f1uc1h2Y7mHsWczXPw5YEvQajJtTbebRDoF4hAv0D4efmhoroCFdUVKK8uNz+v\nrK6sVVkg4sfyau5ocHW3q/HAlQ/gpitucqqjgqX8snx8/NvHWJe6DlvTt6K4ku/xPKDDAEyImoAZ\ng2ZgaOehDVqnToK+hckuzsaivYuwKHERknOT0ca7Dab1m4Zewb3w9IansWzqMkzvN93hes6VnMOx\n3GOIjYh1+ckwALh12a04fO4wDj9yGJvSNmHC4gl4bMRjWHDdgktab7WpGudKzuFs8VlkFWXV6lpq\n+Z0lkLkW7aE8oMCPYW3DMLTT0Cb5HZVWluJA9gGUVZWh2lSNaqqGiUzm53r5CNqhMwgKCiMjR9aq\niTYGIkJ6fjp2ndqFk/knUU3V5nJUm6pRZapClakK1VSNyupK8+sqUxXa+bXDXQPuarTfk4lMSD6X\njO0Z27E9Yzt+zfwV+eX5KK0sRWlVKUorS2sFsC0Dwwbirv534c4Bd6JLuy4NLkfyuWTsytyF/LJ8\n5JXl1fyU56Gsqgy+nr7w8fSBj6eP+bmXhxc8lIf5KEj/LgX6BeKO/ncgOqhh3bFtqayuRMLpBGxM\n24iNaRux/eR2vD/lfcwYNOOi1idB30IREXac2oFFexdhWdIyFFYUorN/Z6Q9nnZJh5iu8vdf/o63\ndr+Fs387i8EfDIaXhxcS/5jo0qMM0TIRESqqK1BaVYqiiiIUlheioLwAhRWFKCwvRFFFEQZ3HIwB\nYfXvamZU5VXlINBF9/ByNugN272ypVJKYVTkKIyKHIU3Jr+BVcmrEBUY5ZYhD/BFU+XV5bj323uR\nnpeOrfdvlZAXViml4OvlC18vXwT6Bbq6OC1CQ5uBLpYEvQu18WmDuwbc5epiXBJ9FMvvjn6Hp0Y+\nhdFdRru4REKIugx5ZaxoPvoolr3b98bcCXNdXBohhDVNEvRKqclKqWSl1HGl1Oym+AzRMkQFRmH2\n6NlYPnV5s3ZZFUI4r9GbbpRSngDeAXA1gFMAflVKrSaiQ439WcL1lFKY97t5ri6GEMKOpqjRjwBw\nnIhSiKgCwFcAbmqCzxFCCOGEpgj6cAAZFq9PadNqUUo9pJRKUEol5OTkNEExhBBCAC48GUtEHxLR\nMCIaFhoa6qpiCCGE4TVF0GcCsLzbRYQ2TQghhAs0RdD/CqCnUipaKeUD4A4Aq5vgc4QQQjih0Xvd\nEFGVUupRAD8D8ATwCRElNfbnCCGEcE6TXBlLRGsArGmKdQshhGgYuTJWCCEMrkWMXqmUygGQfpFv\nbw/A9oDcxiTbfHmQbb48XMo2dyUih90WW0TQXwqlVIIzw3QaiWzz5UG2+fLQHNssTTdCCGFwEvRC\nCGFwRgj6D11dABeQbb48yDZfHpp8m92+jV4IIYR9RqjRCyGEsMOtg/5yuMGJUuoTpVS2UuqgxbRg\npdRapdQx7THIlWVsTEqpSKXURqXUIaVUklLqcW26kbfZTym1Wym1T9vm57Xp0UqpXdr3e5k2pIih\nKKU8lVJ7lVLfa68Nvc1KqTSl1AGlVKJSKkGb1uTfbbcNeosbnFwHoC+AO5VSfV1bqibxKYDJdabN\nBrCeiHoCWK+9NooqAE8RUV8AsQAe0f6uRt7mcgATiWgQgMEAJiulYgHMB/A6EfUAcAHALBeWsak8\nDuCwxevLYZsnENFgiy6VTf7ddtugx2VygxMi2gLgfJ3JNwFYrD1fDODmZi1UEyKiM0T0m/a8EBwC\n4TD2NhMRFWkvvbUfAjARwAptuqG2GQCUUhEAbgDwsfZaweDbbEOTf7fdOeidusGJQYUR0RnteRaA\nMFcWpqkopaIADAGwCwbfZq0JIxFANoC1AE4AyCOiKm0RI36/3wDwDwAm7XUIjL/NBOAXpdQepdRD\n2rQm/243yaBmovkQESmlDNd1SinVFsBKAE8QUQFX9pgRt5mIqgEMVkoFAvgWQG8XF6lJKaWmAMgm\noj1KqfGuLk8zGkNEmUqpDgDWKqWOWM5squ+2O9foL+cbnJxVSnUCAO0x28XlaVRKKW9wyC8hom+0\nyYbeZh0R5QHYCGAkgECllF4ZM9r3ezSAG5VSaeBm14kA3oSxtxlElKk9ZoN36CPQDN9tdw76y/kG\nJ6sB3Kc9vw/AKheWpVFp7bQLARwmov9azDLyNodqNXkopVoBuBp8bmIjgKnaYobaZiL6JxFFEFEU\n+H93AxHdDQNvs1KqjVLKX38O4BoAB9EM3223vmBKKXU9uJ1Pv8HJiy4uUqNTSi0FMB48wt1ZAM8B\n+B+A5QC6gEf9nE5EdU/YuiWl1BgAWwEcQE3b7dPgdnqjbvNA8Ek4T3DlazkRzVFKdQPXdoMB7AVw\nDxGVu66kTUNruvkbEU0x8jZr2/at9tILwJdE9KJSKgRN/N1266AXQgjhmDs33QghhHCCBL0QQhic\nBL0QQhicBL0QQhicBL0QQhicBL0QQhicBL0QQhicBL0QQhjc/wP6mUpVapBvBwAAAABJRU5ErkJg\ngg==\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Time for layer 4, epoch 50, fader 10.0% is 4.66073 sec\n","Time for layer 4, epoch 51, fader 10.2% is 0.28363 sec\n","Time for layer 4, epoch 52, fader 10.4% is 0.24328 sec\n","Time for layer 4, epoch 53, fader 10.6% is 0.21653 sec\n","Time for layer 4, epoch 54, fader 10.8% is 0.20044 sec\n","Time for layer 4, epoch 55, fader 11.0% is 0.19267 sec\n","Time for layer 4, epoch 56, fader 11.2% is 0.19037 sec\n","Time for layer 4, epoch 57, fader 11.4% is 0.19055 sec\n","Time for layer 4, epoch 58, fader 11.6% is 0.19044 sec\n","Time for layer 4, epoch 59, fader 11.8% is 0.19225 sec\n","Time for layer 4, epoch 60, fader 12.0% is 0.18963 sec\n","Time for layer 4, epoch 61, fader 12.2% is 0.19054 sec\n","Time for layer 4, epoch 62, fader 12.4% is 0.19123 sec\n","Time for layer 4, epoch 63, fader 12.6% is 0.19045 sec\n","Time for layer 4, epoch 64, fader 12.8% is 0.19048 sec\n","Time for layer 4, epoch 65, fader 13.0% is 0.18866 sec\n","Time for layer 4, epoch 66, fader 13.2% is 0.19080 sec\n","Time for layer 4, epoch 67, fader 13.4% is 0.18920 sec\n","Time for layer 4, epoch 68, fader 13.6% is 0.18946 sec\n","Time for layer 4, epoch 69, fader 13.8% is 0.19065 sec\n","Time for layer 4, epoch 70, fader 14.0% is 0.19114 sec\n","Time for layer 4, epoch 71, fader 14.2% is 0.18962 sec\n","Time for layer 4, epoch 72, fader 14.4% is 0.19043 sec\n","Time for layer 4, epoch 73, fader 14.6% is 0.19044 sec\n","Time for layer 4, epoch 74, fader 14.8% is 0.19079 sec\n","Time for layer 4, epoch 75, fader 15.0% is 0.19051 sec\n","Time for layer 4, epoch 76, fader 15.2% is 0.19163 sec\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DQGMi1SugN0d","colab_type":"code","colab":{}},"source":["for i in range(3):\n","    test = tf.random.normal([1,noise_dim])\n","    seed_i = i\n","#     test = np.array([seed[seed_i]])\n","\n","    predictions = generator.sigmoid(generator.model_4x4(test, training=False)[1])\n","    print(i)\n","#     print((predictions[0]))\n","    plt.imshow(predictions[0])\n","    plt.show()\n","#     time.sleep(1)\n","#     display.clear_output(wait=True)\n","    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EhGdT3fuW5UQ","colab_type":"code","colab":{}},"source":["test_imgs = []\n","train_dataset = resize(imgs, 64, 49)\n","for x in train_dataset:\n","    test_imgs=x\n","    break\n","\n","test_imgs = np.array(test_imgs)\n","\n","print(test_imgs.shape)\n","\n","plt.imshow(test_imgs[25, :, :, :])\n","\n","plt.show()\n","\n","for i in range(len(test_imgs)):\n","    plt.subplot(7, 7, i+1)\n","    plt.imshow(test_imgs[i, :, :, :])\n","    plt.axis('off')\n","\n","plt.show()\n"],"execution_count":0,"outputs":[]}]}